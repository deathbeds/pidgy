{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPidgin is a literate computing implementation in IPython.  It allows authors to compose their source in the markup language of their choice (e.g. Markdown, RST, Latex).  Narrative, source code, and documentation tests are composed together.\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \"\"\"\n",
    "Pidgin is a literate computing implementation in IPython.  It allows authors to compose their source in the markup language of their choice (e.g. Markdown, RST, Latex).  Narrative, source code, and documentation tests are composed together.\n",
    "\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "    __all__ = 'Pidgin',"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "    _run_as_main =  __name__ == '__main__'\n",
    "    _run_as_script = _run_as_main and globals().get('__file__', None) in __import__('sys').argv\n",
    "    _run_as_interactive = _run_as_main and not _run_as_script    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import ast, textwrap, re, doctest, functools, collections, contextlib, sys\n",
    "    import pandocfilters, traitlets, IPython, nbconvert, jinja2.meta, jinja2.ext\n",
    "    import importnb, htmlmin, xonsh\n",
    "    \n",
    "    get_ipython = IPython.get_ipython\n",
    "    shell = get_ipython()\n",
    "\n",
    "    pidgin=\\\n",
    "    10 and _run_as_interactive and __import__('pidgin').load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocab\n",
    "\n",
    "## Pidgin programming\n",
    "\n",
    "* The input generates the output, but is ignored in publishing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n## The `IPython` pidgin implementation\\n\\n### `IPython` as a literate computing implementation.\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \"\"\"\n",
    "## The `IPython` pidgin implementation\n",
    "\n",
    "### `IPython` as a literate computing implementation.\n",
    "    \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Markup application language\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "    input_formats = !pandoc --list-input-formats\n",
    "    output_formats = !pandoc --list-output-formats    \n",
    "\n",
    "    def translate(source=None, input='markdown', target='rst', file=None, args='', *, lang='ipython'):\n",
    "        if callable(target): return target(source)\n",
    "        import json, subprocess\n",
    "        process = subprocess.Popen(['pandoc', f'--read={input}', f'--write={target}', *F\"--indented-code-classes={lang} {args}\".rstrip().split()], stdin=subprocess.PIPE, stdout=subprocess.PIPE)\n",
    "        returns = process.communicate(source.encode())[0].decode()\n",
    "        if target in {'json'}: return json.loads(returns)\n",
    "        return returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def python(source, input='markdown'):\n",
    "        if should_not_transform_source(source): return source\n",
    "        def action(type, value, format, metadata):\n",
    "            nonlocal code, remaining, min_indent\n",
    "            if type == 'CodeBlock':\n",
    "                if ''.join(value[0][1]) == 'ipython':\n",
    "                    splitter = re.compile(''.join(\"\\\\s{0,4}%s\\\\s*\"%re.escape(x) for x in value[1].splitlines() if x.strip()))\n",
    "\n",
    "                    try: before, after = re.split(splitter, remaining, 1)\n",
    "                    except:  before = after = ''\n",
    "                    current = len(after) and remaining[len(before):-len(after)] or remaining[len(before):]\n",
    "                    if current.lstrip().startswith('```'): return\n",
    "                    remaining = after\n",
    "\n",
    "                    # Extract the first line of the current code block.\n",
    "                    first_line = get_first_line(current)\n",
    "                    # Construct the code we'll \n",
    "                    current, body = ''.join(current), ''.join(before)\n",
    "\n",
    "                    # The previous last line append\n",
    "                    last_line = get_last_line(code.splitlines())\n",
    "\n",
    "                    if not last_line.endswith(('\"'*3, \"'\"*3, '-'*3, '\"'*3+\"\\\\\", \"'\"*3+'\\\\',)): body = quote(body, '')\n",
    "\n",
    "                    definition = last_line.rstrip().endswith(':')\n",
    "\n",
    "                    this_indent = get_line_indent(first_line)                  \n",
    "                    min_indent = min_indent or this_indent\n",
    "\n",
    "                    # The current indent level so far.\n",
    "                    prior_indent = get_line_indent(last_line) or min_indent\n",
    "\n",
    "                    if this_indent < min_indent:\n",
    "                        current = textwrap.indent(current, ' '*(min_indent-this_indent))\n",
    "                        this_indent = get_line_indent(get_first_line(current.splitlines()))\n",
    "\n",
    "                    indent = max(min_indent, (has_return(code) and min or max)(prior_indent, this_indent))        \n",
    "                    if definition:\n",
    "                        if prior_indent >= indent: indent = (prior_indent + 4)\n",
    "                        body = hanging_indent(textwrap.indent(body, ' '*min_indent), ' '*(indent-min_indent))\n",
    "                    else: body = textwrap.indent(body, ' '*indent)\n",
    "\n",
    "                    code += body+current\n",
    "                    \n",
    "        remaining, code, min_indent = source, \"\"\"\"\"\", 0\n",
    "        pandocfilters.walk(translate(source, input, 'json'), action, 'python', {})\n",
    "        if remaining.strip(): code += textwrap.indent(quote(remaining), ' '*min_indent).rstrip() + ';'\n",
    "        return textwrap.dedent(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "    class Extension(traitlets.HasTraits):\n",
    "        \"\"\"\n",
    "Extension\n",
    "\n",
    "IPython extension\n",
    "IPython events\n",
    "Magics\n",
    "Transformers\n",
    "Observable objects.\n",
    "\n",
    "    \"\"\"\n",
    "        shell = traitlets.Instance(IPython.InteractiveShell, help=\"\"\"\"\"\", allow_none=True)\n",
    "        enabled = traitlets.Bool(True, help=\"\"\"\"\"\")\n",
    "        \n",
    "        def __init__(self, shell=None, **kwargs):\n",
    "            traitlets.HasTraits.__init__(self, **kwargs)\n",
    "            self.is_extension() and self.load_ipython_extension(self.shell)\n",
    "            for trigger in self.triggers(): self.shell.events.register(trigger, getattr(self, trigger))\n",
    "\n",
    "        @traitlets.default('shell')\n",
    "        def _default_shell(self): return IPython.get_ipython()\n",
    "\n",
    "        @traitlets.observe('enabled')\n",
    "        def _observe_enabled(self, change=None): \n",
    "            if self.is_extension(): self.load_ipython_extension(self.shell) if change['new'] else self.unload_ipython_extension(self.shell) \n",
    "                \n",
    "        def __enter__(self): self.enabled or self.load_ipython_extension(self.shell)            \n",
    "        def __exit__(self, *e): self.enabled or self.unload_ipython_extension(self.shell)\n",
    "            \n",
    "        def is_extension(self): return hasattr(self, 'load_ipython_extension') and self.enabled\n",
    "        \n",
    "        def triggers(self): return list(object for object in IPython.core.events.available_events if hasattr(self, object))\n",
    "\n",
    "    def load_ipython_extension(shell): pidgin_shell.enabled = True\n",
    "    \n",
    "    load = functools.partial(load_ipython_extension, shell)\n",
    "\n",
    "    def unload_ipython_extension(shell): pidgin_shell.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "    class Tangle(Extension):\n",
    "        input = traitlets.Enum(input_formats, 'markdown')\n",
    "        def translate(self, source, target): \n",
    "            return target(source) if callable(target) else translate(source, self.input, target)\n",
    "        python = functools.partialmethod(translate, target=python)\n",
    "    \n",
    "        def __call__(self, lines): return self.python(''.join(lines)).splitlines(True)\n",
    "        \n",
    "        def load_ipython_extension(self, shell): remove_doctest_cleanup(shell.input_transformer_manager), shell.input_transformer_manager.cleanup_transforms.insert(0, self)\n",
    "            \n",
    "        def unload_ipython_extension(self, shell): shell.input_transformer_manager.cleanup_transforms = [object for object in shell.input_transformer_manager.cleanup_transforms if not isinstance(object, Tangle)]\n",
    "            \n",
    "    [setattr(Tangle, object, functools.partialmethod(Tangle.translate, target=object)) for object in input_formats];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bash as a systems level language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "    class Bash(Extension):\n",
    "        def load_ipython_extension(self, shell): remove_system_assign(shell), xonsh.main.setup();shell.compile = self.CachingCompiler()\n",
    "        def unload_ipython_extension(self, shell): shell.compile = IPython.core.compilerop.CachingCompiler()\n",
    "\n",
    "        class CachingCompiler(IPython.core.compilerop.CachingCompiler):\n",
    "            def ast_parse(self, source, filename='<unknown>', symbol='exec'): return __import__('builtins').__xonsh__.execer._parse_ctx_free(source, symbol, filename)[0]\n",
    "            \n",
    "    def remove_system_assign(shell):  \n",
    "        for i, transformer in enumerate(shell.input_transformer_manager.token_transformers): isinstance(transformer, type) and issubclass(transformer, IPython.core.inputtransformer2.SystemAssign) and shell.input_transformer_manager.token_transformers.pop(i); break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def remove_doctest_cleanup(input_transformer_manager):  \n",
    "        for i, transformer in enumerate(input_transformer_manager.cleanup_transforms):\n",
    "            try:\n",
    "                if transformer.initial_re.pattern[1:4] == '>>>': input_transformer_manager.cleanup_transforms.pop(i); break\n",
    "            except: ...\n",
    "\n",
    "    def quote(str: str, punc: str='') -> str:\n",
    "        str, leading_ws = ''.join(str), []\n",
    "        lines = str.splitlines(True)\n",
    "        _ = '\"'*3\n",
    "        if _ in str: _ = \"'\"*3 # it seems quotes are a problem\n",
    "        if not str.strip(): _ = punc = ''\n",
    "        while lines and (not lines[0].strip()): leading_ws.append(lines.pop(0))    \n",
    "        str = ''.join(lines)\n",
    "        end = len(str.rstrip())\n",
    "        str, ending_ws = str[:end], str[end:]\n",
    "        if str and str.endswith(_[0]): str += ' '                    \n",
    "        return F\"{''.join(leading_ws)}{_}{str}{_}{punc}{ending_ws}\"\n",
    "\n",
    "    def get_first_line(lines: (str, list), line: str='') -> str:\n",
    "        if not isinstance(lines, (reversed, list)): lines = lines.splitlines()\n",
    "        for line in lines or ['']: \n",
    "            if line.strip(): break\n",
    "        return line\n",
    "\n",
    "    def get_last_line(lines, line=''): return get_first_line(lines[::-1], line)\n",
    "\n",
    "    def get_line_indent(line: str) -> int:   return len(line) - len(line.lstrip())\n",
    "\n",
    "    def has_return(code: str) -> bool:\n",
    "        code = '\\n'.join(code)\n",
    "        if 'return ' not in code: return False\n",
    "        code = importnb.loader.dedent(code)\n",
    "        try:\n",
    "            node = ast.parse(code)\n",
    "            while hasattr(node, 'body'): node = node.body[-1]\n",
    "            return isinstance(node, ast.Return)\n",
    "        except: ...\n",
    "\n",
    "    def hanging_indent(str, indent: str, *, out=\"\"\"\"\"\") -> str:\n",
    "        for line in str.splitlines(True):\n",
    "            if not line.strip(): out += line\n",
    "            else:\n",
    "                if out.strip(): out += line\n",
    "                else: out += indent+line\n",
    "        return out\n",
    "    \n",
    "    def strip_blank_lines(str): return '\\n'.join(str if str.strip() else '' for str in ''.join(str).splitlines())\n",
    "\n",
    "    def should_not_transform_source(str): return str.startswith('%%')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Documentation testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def run_docstring_examples(str, shell, verbose=False, compileflags=None):\n",
    "        runner = doctest.DocTestRunner(verbose=verbose, optionflags=doctest.ELLIPSIS)\n",
    "        globs = vars(shell.user_module); tests = []\n",
    "        for finder in (doctest.DocTestFinder(verbose, InlineDoctestParser()), doctest.DocTestFinder(verbose)):\n",
    "            tests.extend(finder.find(str, name=shell.user_module.__name__))\n",
    "        with wrapped_compiler(shell):\n",
    "            for test in tests: test.globs = globs;  runner.run(test, compileflags=compileflags, clear_globs=False)\n",
    "        return runner\n",
    "\n",
    "    @contextlib.contextmanager\n",
    "    def wrapped_compiler(shell):\n",
    "        def compiler(input, filename, symbol, *args, **kwargs):\n",
    "            nonlocal shell\n",
    "            return shell.compile(ast.Interactive(body=shell.transform_ast(shell.compile.ast_parse(shell.transform_cell(textwrap.indent(input, ' '*4)))).body), filename, 'single' )\n",
    "        yield setattr(doctest, 'compile', compiler)\n",
    "        try: doctest.compile = compile\n",
    "        except: ...\n",
    "\n",
    "    class InlineDoctestParser(doctest.DocTestParser):\n",
    "        _tick_ = \"`\"    \n",
    "        _EXAMPLE_RE = re.compile(F'{_tick_}(?P<indent>)(?P<source>[^{_tick_}]+){_tick_}')\n",
    "        def _parse_example(self, m, name, lineno): return m.group('source'), None, '...', None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "    class Doctest(Extension):                            \n",
    "        def post_run_cell(self, result, *a, **kwargs): return run_docstring_examples(result.info.raw_cell, self.shell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n### Formatting and Weaving pidgin programs.\\n\\nModifies the application language.\\n\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \"\"\"\n",
    "### Formatting and Weaving pidgin programs.\n",
    "\n",
    "Modifies the application language.\n",
    "\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "    class Formatter(IPython.core.formatters.DisplayFormatter):\n",
    "        def __init__(self, *a, **k):\n",
    "            super().__init__(*a, **k)\n",
    "            for object in (\n",
    "                ('matplotlib.figure', 'Axes', _show_axes),\n",
    "                ('matplotlib.figure', 'Figure', _show_axes),\n",
    "                ('matplotlib.axes._subplots', 'AxesSubplot', _show_axes),\n",
    "                ('sympy.plotting.plot', 'Plot', _show_sympy_axes),\n",
    "            ): self.mimebundle_formatter.for_type_by_name(*object)\n",
    "                \n",
    "        def finalize(self, object) -> str:\n",
    "            if isinstance(object, str): \n",
    "                new = self.parent.user_ns.get(object, object)\n",
    "                if new == object: return object\n",
    "                if isinstance(new, str): return self.finalize(new)\n",
    "                \n",
    "            bundle, metadata = self.format(object)\n",
    "            for type in [str for str in reversed(self.active_types) if str != 'text/plain']:\n",
    "                if type in bundle: \n",
    "                    object = bundle[type]\n",
    "                    if type.startswith('image') and ('svg' not in type):  object = _format_images(type, bundle)\n",
    "                    if type == 'text/latex': \n",
    "                        if object.startswith('$$') and object.endswith('$$'): object = object[1:-1]\n",
    "                    if type =='text/html': object = htmlmin.minify(object, remove_empty_space=True)\n",
    "                    break\n",
    "            return object\n",
    "        \n",
    "    def _show_axes(object):\n",
    "        import matplotlib.backends.backend_svg; bytes = __import__('io').BytesIO()\n",
    "        matplotlib.backends.backend_agg.FigureCanvasAgg(getattr(object, 'figure', object)).print_png(bytes)\n",
    "        return _format_bytes(bytes.getvalue(), object)\n",
    "\n",
    "    def _show_sympy_axes(object): \n",
    "        s = __import__('io').BytesIO()\n",
    "        object.save(s)\n",
    "        return _format_bytes(s.getvalue(), object)\n",
    "\n",
    "    def _format_bytes(bytes, object):\n",
    "        return {'text/html': _format_images('image/png', {'image/png': bytes}), 'text/plain': repr(object),}, {}\n",
    "\n",
    "    def _format_images(type, bundle):\n",
    "        str = bundle[type]        \n",
    "        if isinstance(str, bytes): str = __import__('base64').b64encode(str).decode('utf-8')\n",
    "        if type in ('image/svg+xml', 'text/html'):  ...\n",
    "        elif str.startswith('http'): str = F\"\"\"<img src=\"{str}\"/>\"\"\"\n",
    "        else: str = F\"\"\"<img src=\"data:{type};base64,{str}\"/>\"\"\"\n",
    "        return str\n",
    "    \n",
    "    __formatter__ = Formatter(parent=shell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def import_yaml():\n",
    "        try: from ruamel import yaml\n",
    "        except: \n",
    "            try: import yaml\n",
    "            except:...\n",
    "        return yaml\n",
    "\n",
    "    def front_matter(source):\n",
    "        try:\n",
    "            if source.startswith('---\\n') and (source.rindex('\\n---\\n') > 0):\n",
    "                data, sep, rest = source.lstrip('-').partition('\\n---\\n')\n",
    "                data = import_yaml().safe_load(__import__('io').StringIO(data))\n",
    "                if isinstance(data, dict): return rest, data\n",
    "        except ValueError: ...\n",
    "        return source, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    class Weave(Extension):\n",
    "        display_formatter = traitlets.Instance(IPython.core.formatters.DisplayFormatter)\n",
    "        observable = traitlets.Instance(traitlets.HasTraits)\n",
    "        environment = traitlets.Instance(jinja2.Environment, allow_none=True)\n",
    "        input = traitlets.Enum(input_formats, 'markdown')\n",
    "        \n",
    "        @traitlets.default('environment')\n",
    "        def _default_environment(self): return create_environment()\n",
    "        \n",
    "        @traitlets.default('observable')\n",
    "        def _default_observable(self): global __observable__; return __observable__\n",
    "        \n",
    "        @traitlets.default('display_formatter')\n",
    "        def _default_formatter(self): global __formatter__; return __formatter__\n",
    "        \n",
    "        def render(self, source, **k):\n",
    "            source, metadata = front_matter(source)\n",
    "            def finalize(ctx, object): return self.display_formatter.finalize(object)\n",
    "            \n",
    "            finalize.contextfunction = finalize.evalcontextfunction = finalize.environmentfunction = True\n",
    "            \n",
    "            template = self.environment.overlay(finalize=finalize).from_string(source)\n",
    "            display_id = IPython.display.DisplayHandle()\n",
    "\n",
    "            def update(change=None, init=False):\n",
    "                nonlocal source, self, display_id, template, k, metadata\n",
    "                object = template.render(**collections.ChainMap(k, metadata, self.shell.user_ns, self.shell.user_ns.get('__annotations__', {}), vars(__import__('builtins'))))\n",
    "                data = {'text/html': translate(object, self.input, 'html'), 'text/plain': source,}\n",
    "                getattr(display_id, init and 'display' or 'update')(data, metadata=metadata, raw=True)\n",
    "                \n",
    "            update(init=True)            \n",
    "            \n",
    "            undeclared = jinja2.meta.find_undeclared_variables(template.environment.parse(source))\n",
    "            if undeclared:\n",
    "                for var in undeclared: self.observable.has_trait(var) or self.observable.add_traits(**{var: traitlets.Any()})\n",
    "                self.observable.observe(update, undeclared)\n",
    "        \n",
    "        def post_run_cell(self, result): self.enabled and result.info.raw_cell.splitlines()[0].strip() and self.render(result.info.raw_cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def create_environment(): return nbconvert.TemplateExporter().environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    class Observable(traitlets.HasTraits):\n",
    "        shell = traitlets.Instance(IPython.InteractiveShell)\n",
    "        def __init__(self, *a, **k): super().__init__(*a, **k), self.shell.events.register('post_execute', self)\n",
    "        def __call__(self, change=None): [setattr(self, trait, self.shell.user_ns.get(trait, None)) for trait in self.traits()]\n",
    "                \n",
    "    __observable__ = Observable(shell=shell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Readable and reusable pidgin docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    class PreProcessor(nbconvert.preprocessors.Preprocessor):\n",
    "        target = traitlets.Any(default_value='rst')\n",
    "        def preprocess_cell(self, cell, metadata, id):\n",
    "            if cell['cell_type'] in {'code', 'markdown'}:\n",
    "                _, source = metadata['metadata']['name'].rsplit('.', 1)\n",
    "                if source == 'md': source = 'markdown'\n",
    "                cell['source'] = translate(cell['source'], source, self.target)\n",
    "            return cell, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    class PidginMixin:\n",
    "        extensions = '.md.ipynb', '.rst.ipynb', '.textile.ipynb'\n",
    "        splitter = IPython.core.inputtransformer2.TransformerManager()\n",
    "        remove_doctest_cleanup(splitter)\n",
    "        def code(self, str: str) -> str:  \n",
    "            global splitter\n",
    "            try: _, format, __ = self.path.rsplit('.')\n",
    "            except: format = 'markdown'\n",
    "            if format == 'md': format='markdown'\n",
    "            return self.splitter.transform_cell(python(str))\n",
    "        \n",
    "\n",
    "    class Pidgin(PidginMixin, importnb.Notebook): ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Command line usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    class PidginParameterize(PidginMixin, importnb.Parameterize): ...\n",
    "\n",
    "    if _run_as_script:\n",
    "        \"\"\"\n",
    "Command line usage.\n",
    "\n",
    "        \"\"\"\n",
    "        sys.argv = sys.argv[1:]\n",
    "        PidginParameterize.load(sys.argv[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    class InteractiveShell(Extension):\n",
    "        extensions = traitlets.List()\n",
    "        @traitlets.default('extensions')\n",
    "        def _default_extensions(self): return [object(enabled=False, shell=self.shell) for object in (Tangle, Bash, Doctest, Weave)]\n",
    "        \n",
    "        def load_ipython_extension(self, shell, bool=True): \n",
    "            for object in self.extensions: object.enabled = bool\n",
    "                \n",
    "        unload_ipython_extension = functools.partialmethod(load_ipython_extension, bool=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    pidgin_shell = InteractiveShell(enabled=False, shell=shell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook pidgin.ipynb to python\n",
      "[NbConvertApp] Writing 18185 bytes to pidgin.py\n",
      "Fixing /Users/tonyfast/pidgin/pidgin.py\n"
     ]
    }
   ],
   "source": [
    "    ## Developer\n",
    "\n",
    "    if _run_as_interactive:\n",
    "        !jupyter nbconvert --to python --TemplateExporter.exclude_input_prompt=True pidgin.ipynb\n",
    "        !isort pidgin.py\n",
    "        !black pidgin.py\n",
    "        !pyflakes pidgin.py && echo \"üèãÔ∏è‚Äç‚ôÄÔ∏è\"\n",
    "        !pyreverse -my -opng  -ppidgin pidgin\n",
    "        IPython.display.display(IPython.display.Image('classes_pidgin.png', embed=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p6",
   "language": "python",
   "name": "p6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
