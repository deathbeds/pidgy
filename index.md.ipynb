{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interactive computing as a medium for modeling ideas as computational literature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# `pidgy` programming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<!--\n",
       "    \n",
       "    import pidgy, pathlib, nbconvert, IPython\n",
       "\n",
       "    load = lambda x, level=1: demote(pathlib.Path(x.__file__).read_text(), level)\n",
       "    demote = lambda x, i: ''.join(\n",
       "        '#'*i + x if x.startswith('#') else x for x in x.splitlines(True)\n",
       "    )\n",
       "\n",
       "    def load(x, level=1):\n",
       "        file = getattr(x, '__file__', x)\n",
       "        name = getattr(x, '__name__', x)\n",
       "        object = demote(\n",
       "            pathlib.Path(file).read_text()\n",
       "            if file.endswith('.md')\n",
       "            else nbconvert.get_exporter('markdown')(exclude_input=True).from_filename(file)[0], level) \n",
       "        if object.startswith('---'): fm, sep, object = object.lstrip('---').partition('---')\n",
       "            \n",
       "        object = str.replace(object, '# ', F'# [<code>[source]</code>]({pathlib.Path(file).relative_to(pathlib.Path().absolute())})', 1)\n",
       "        return object\n",
       "    \n",
       "\n",
       "\n",
       "    with pidgy.pidgyLoader(lazy=True):\n",
       "        import pidgy.pytest_config.readme, pidgy.tests.test_pidgin_syntax, pidgy.tests.test_basic, pidgy.tests.test_repl\n",
       "        import docs.readme\n",
       "\n",
       "-->"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    \n",
    "    import pidgy, pathlib, nbconvert, IPython\n",
    "\n",
    "    load = lambda x, level=1: demote(pathlib.Path(x.__file__).read_text(), level)\n",
    "    demote = lambda x, i: ''.join(\n",
    "        '#'*i + x if x.startswith('#') else x for x in x.splitlines(True)\n",
    "    )\n",
    "\n",
    "    def load(x, level=1):\n",
    "        file = getattr(x, '__file__', x)\n",
    "        name = getattr(x, '__name__', x)\n",
    "        object = demote(\n",
    "            pathlib.Path(file).read_text()\n",
    "            if file.endswith('.md')\n",
    "            else nbconvert.get_exporter('markdown')(exclude_input=True).from_filename(file)[0], level) \n",
    "        if object.startswith('---'): fm, sep, object = object.lstrip('---').partition('---')\n",
    "            \n",
    "        object = str.replace(object, '# ', F'# [<code>[source]</code>]({pathlib.Path(file).relative_to(pathlib.Path().absolute())})', 1)\n",
    "        return object\n",
    "    \n",
    "\n",
    "\n",
    "    with pidgy.pidgyLoader(lazy=True):\n",
    "        import pidgy.pytest_config.readme, pidgy.tests.test_pidgin_syntax, pidgy.tests.test_basic, pidgy.tests.test_repl\n",
    "        import docs.readme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "toc-hr-collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## [<code>[source]</code>](docs/readme.md)Abstract\n",
       "\n",
       "`pidgy` presents a fun and expressive interactive literate programming approach\n",
       "for computational literature, that is also a valid programs.\n",
       "A literate program is implicitly multilingual, a document formatting language\n",
       "and programming language are defined as the substrate for the\n",
       "literate programming language.\n",
       "\n",
       "The original 1979 implementation defined the [WEB] metalanguage\n",
       "of [Latex] and [Pascal]. `pidgy` is modern and interactive\n",
       "take on [Literate Programming] that uses [Markdown] and [Python]\n",
       "as the respective document and programming languages,\n",
       "of course we'll add some other bits and bobs.\n",
       "\n",
       "This conceptual work treats the program as literature and literature\n",
       "as programs. The result of the `pidgy` implementation is an interactive programming\n",
       "experience where authors design and program simultaneously in [Markdown].\n",
       "An effective literate programming will use machine logic to supplement\n",
       "human logic to explain a program program.\n",
       "If the document is a valid module (ie. it can restart and run all),\n",
       "the literate programs can be imported as [Python] modules\n",
       "then used as terminal applications, web applications,\n",
       "formal testing object, or APIs. All the while, the program\n",
       "itself is a readable work of literature as html, pdf.\n",
       "\n",
       "`pidgy` is written as a literate program using [Markdown]\n",
       "and [Python].\n",
       "Throughout this document we'll discuss\n",
       "the applications and methods behind the `pidgy`\n",
       "and what it takes to implement a [Literate Programming]\n",
       "interface in `IPython`.\n",
       "\n",
       "## Topics\n",
       "\n",
       "- Literate Programming\n",
       "- Computational Notebooks\n",
       "- Markdown\n",
       "- Python\n",
       "- Jupyter\n",
       "- IPython\n",
       "\n",
       "## Author\n",
       "\n",
       "[Tony Fast]\n",
       "\n",
       "<!--\n",
       "\n",
       "    import __init__ as paper\n",
       "    import nbconvert, pathlib, click\n",
       "    file = pathlib.Path(locals().get('__file__', 'readme.md')).parent / 'index.ipynb'\n",
       "\n",
       "    @click.group()\n",
       "    def application(): ...\n",
       "\n",
       "    @application.command()\n",
       "    def build():\n",
       "        to = file.with_suffix('.html')\n",
       "        to.write_text(\n",
       "            nbconvert.get_exporter('html')(\n",
       "                exclude_input=True).from_filename(\n",
       "                    str(file))[0])\n",
       "        click.echo(F'Built {to}')\n",
       "    import subprocess\n",
       "\n",
       "\n",
       "    @application.command()\n",
       "    @click.argument('files', nargs=-1)\n",
       "    def push(files):\n",
       "        click.echo(__import__('subprocess').check_output(\n",
       "                F\"gist -u 2947b4bb582e193f5b2a7dbf8b009b62\".split() + list(files)))\n",
       "\n",
       "    if __name__ == '__main__':\n",
       "        application() if '__file__' in locals() else application.callback()\n",
       "\n",
       "\n",
       "-->\n",
       "\n",
       "[tony fast]: #\n",
       "[markdown]: #\n",
       "[python]: #\n",
       "[jupyter]: #\n",
       "[ipython]: #\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "{{load(docs.readme)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## [<code>[source]</code>](docs/intro.md)Introduction\n",
       "\n",
       "[Fernando Perez], creator of [`IPython`], wrote an essay titled [\"Literate computing\" and computational reproducibility]. Here he introduces the term [Literate Computing] that describes a style of workflow where representations of live computation are critical to the understanding of a computational narrative. At the scale of interactive computing, we focus on documenting the computational thinking process using narrative, code, and hypermedia. Whereas [Literate Programming] considers the enduring literary qualities of the program. In this work, we discuss the `pidgy` interactive shell that is designed to improve the [Literate Computing] experience so that the outcome are multi-objective readable, reproducible, and reusable [Literate Program]s.\n",
       "\n",
       "![](literate_computing_venn.jpeg)\n",
       "\n",
       "[Literate Programming] and [Literate Computing] shine light on perspectives on computational thinking as [Documentation]. These concerns represent passive and active states of computational document, literature is the resting state and computing is interactive state. In either condition, `pidgy` prefers the use of Markdown as the interface for composing literate programs. While interactive computing, the input represents both a display object and python code. Interactively writing [Markdown] allows for a fluid intertextuality of `\"code\"`, hyperlinks, and hypermedia in human logic, an implicit outcome is a [Markdown] document that has literary and computational qualities.\n",
       "\n",
       "To remain consistent with [Literate Programming], `pidgy` defines the [Tangle] and [Weave] steps that convert the input [Markdown] to their document and program translations. Often [Literate Computing] is used as an informal test of thinking. `pidgy` codifies interactive testing practices that improve the expectation that a [Literate Program] is reusable or reproducible. The [Weave] step in `pidgy` is a enriched with a [Templating Language] that allows computable objects to be embedded and formatted into [Markdown] source.\n",
       "\n",
       "![](tangle_weave_diagram.svg)\n",
       "\n",
       "The [Tangle] step of literate programming converts translates the documentation language into the programming language. The original 1979 [`\"WEB\"`][web] implementation chose [$\\TeX{}$][tex] and [PASCAL], and `pidgy` chooses [Markdown] and [Python]. `pidgy` applies line-for-line heuristics that format `not \"code\"` blocks into block strings relative block code objects in the literate input.\n",
       "\n",
       "Before [Weaving] code, `pidgy` executes formal `doctest` and `unittest` discovered by the customized test suite. Testing code interactively helps to ensure that entire documents are reusable as programs. These tests do not hault the program, rather they consider the standard error message to be a feature of readable literature that can communicate exceptions.\n",
       "\n",
       "To [Weave] a document refers to the transforms made to the input as it becomes a readable object. `pidgy` provides the ability include representation of live programming objects directly in the [Markdown] using `jinja2` syntax. [Markdown] can represent literate programs written in many languages. [Markdown] can include HTML and CSS.\n",
       "\n",
       "![](pidgy_literate_computing.jpeg)\n",
       "\n",
       "Throughout this work we'll design a purpose built interactive literate computing interface. This work is interested in designing an interactive experience that results in multi-objective computational documents that are readable, reusable, and reproducible over longer timelines than single use notebooks and programs.\n",
       "\n",
       "The intent of `pidgy` matured as different features began to take form. Originally, `pidgy` was gungho about [Notebooks] being the primary interface for Literate Programming. [Notebooks] provide a metastable serialization of the Literate Programming containing both the literate input and the woven hypermedia. And they still serve valid applications for conditions where the input and output are highly dependent on each other. There are other conditions where we desire to write programmatic literature that is reliably reproducible over a longer timeline. [Markdown] written in `pidgy` seems to provide a compact input for pythonic literate programs with [Markdown] first. If a program is reproducible, then it is input of its outputs.\n",
       "\n",
       "![](degrees_of_freedom.jpg)\n",
       "\n",
       "[\"literate computing\" and computational reproducibility]: http://blog.fperez.org/2013/04/literate-computing-and-computational.html\n",
       "[tools for the life cycle of a computational idea]: https://sinews.siam.org/Details-Page/jupyter-tools-for-the-life-cycle-of-a-computational-idea\n",
       "[tex]: #\n",
       "[web]: #\n",
       "[pascal]: #\n",
       "[markdown]: #\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "{{load(docs.intro)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "toc-hr-collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## [<code>[source]</code>](pidgy/extension.md)Configuring the [Markdown]-forward interactive shell in `IPython`\n",
       "\n",
       "This sections registers and describes each of the extensions that `pidgy` applies to the interactive shell.\n",
       "The implementations of the extension are shaped by existing open source software and practices, and run throughout all aspects of the `pidgy` project. Specifically, this work relies on tooling from the scientific [Python] community.\n",
       "\n",
       "<!--excerpt-->\n",
       "\n",
       "`IPython` is a keystone application in the scientific python computing system and is one of the heritage langauges that evolved in the award winning `jupyter` project. The `ipykernel and IPython` are configurable [Python] objects that prescribe how code is executed while interactive computing. The `pidgy` extension is a collection of individual documents that configure individual components of the [Read-Eval-Print-Loop] application.\n",
       "\n",
       "    import IPython, importnb\n",
       "\n",
       "Each module in `pidgy` is an `IPython` configuration module that transforms independent aspects of [Literate Computing].\n",
       "\n",
       "<details><summary>What are the <code>load_ipython_extension and unload_ipython_extension</code> </summary>\n",
       "`load_ipython_extension and unload_ipython_extension` are used by `IPython` to trigger modifications to the interactive shell by a module. These methods are inovked by the `\"load_ext reload_ext unload_ext\"` line magics. Demonstrated in the following, the `load_ipython_extension` recieves the current `IPython.InteractiveShell` as an argument to be configured.\n",
       "</details>\n",
       "\n",
       "    def load_ipython_extension(shell: IPython.InteractiveShell) -> None:\n",
       "\n",
       "The `extension` module aggregates the extensions that were designed for `pidgy`.\n",
       "Currently, `pidgy` defines 6 extensions to produce the enhanced literate programming experience. Each module configures isoluted components of the `IPython.InteractiveShell`.\n",
       "\n",
       "        with importnb.Notebook():\n",
       "            try: from . import loader, tangle, extras\n",
       "            except: import loader, tangle, extras\n",
       "        with loader.pidgyLoader():\n",
       "            try: from . import weave, testing, metadata\n",
       "            except: import weave, testing, metadata\n",
       "        ...\n",
       "\n",
       "- `loader` ensures the ability to important python, markdown, and notebook documents\n",
       "- `tangle` defines the heuristics for translating [Markdown] to [Python].\n",
       "- `extras` introduces experimental syntaxes specific to `pidgy`.\n",
       "- `metadata` retains information as the shell and kernel interact with each other.\n",
       "- `testing` adds unittest and doctest capabilities to each cell execution.\n",
       "- `weave` defines a [Markdown] forward display system that templates and displays the input.\n",
       "\n",
       "        loader.load_ipython_extension(shell)\n",
       "        tangle.load_ipython_extension(shell)\n",
       "        metadata.load_ipython_extension(shell)\n",
       "        extras.load_ipython_extension(shell)\n",
       "        testing.load_ipython_extension(shell)\n",
       "        weave.load_ipython_extension(shell)\n",
       "\n",
       "\n",
       "    def unload_ipython_extension(shell):\n",
       "\n",
       "`unload_ipython_extension` unloads all the extensions loads in `load_ipython_extension`.\n",
       "\n",
       "        with importnb.Notebook():\n",
       "            try: from . import loader, tangle, extras\n",
       "            except: import loader, tangle, extras\n",
       "        with loader.pidgyLoader():\n",
       "            try: from . import weave, testing, metadata\n",
       "            except: import weave, testing, metadata\n",
       "\n",
       "        [x.unload_ipython_extension(shell) for x in (loader, weave, testing, extras, metadata, tangle)]\n",
       "\n",
       "[markdown]: #\n",
       "[literate programming]: #\n",
       "[`ipython`]: #\n",
       "[`jupyter`]: #\n",
       "[kernels]: https://github.com/jupyter/jupyter/wiki/Jupyter-kernels\n",
       "[`ipython` extensions]: https://ipython.readthedocs.io/en/stable/config/extensions/\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "{{load(pidgy.extension)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "![](pidgyrepl.jpg)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "![](pidgyrepl.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## [<code>[source]</code>](pidgy/tests/test_repl.md)Stepping along `IPython`'s [Read-Eval-Print-Loop]\n",
       "\n",
       "> Sometimes I think the only universal in the computing field is the fetch-execute cycle.\n",
       ">\n",
       "> > _Alan Perlis - Perlisisms_\n",
       "\n",
       "The [Read-Eval-Print-Loop], a fetch-execute cycle, is a familiar interface to execute code and\n",
       "programs run by a compiler. The `IPython` project orginally began as an\n",
       "terminal application that was designed to improve the interactive experience\n",
       "when working [Python]. Eventually, `IPython` moved outside the terminal and\n",
       "into the browser with `IPython` notebooks that allowed authors that capture\n",
       "the process of their computational thinking supplemented with supporting\n",
       "hypermedia.\n",
       "\n",
       "    import pytest\n",
       "    @pytest.mark.skipif(not __import__('IPython').get_ipython(), \"There is no IPython.\")\n",
       "    def test_ipython_repl():\n",
       "\n",
       "The body `IPython_REPL` demonstrates that components of the interactive shell that may be configured.\n",
       "\n",
       "        shell = IPython.get_ipython()\n",
       "\n",
       "#### Read\n",
       "\n",
       "`IPython` triggers events when the REPL begins.\n",
       "\n",
       "        shell.events.callbacks.get('pre_execute'), shell.events.callbacks.get('pre_run_cell')\n",
       "\n",
       "Once the `input` is read, `IPython` applies a series of strings transformations when the cell is transformed.\n",
       "The outcome of the transformation should be some that [Python] can `compile`.\n",
       "\n",
       "        shell.transform_cell, [\n",
       "            shell.input_transformer_manager.cleanup_transforms,\n",
       "            shell.input_transformer_manager.line_transforms,\n",
       "            shell.input_transformer_manager.token_transformers\n",
       "        ]\n",
       "\n",
       "The [Python] code is translated into an [Abstract Syntax Tree].\n",
       "\n",
       "        shell.compile.ast_parse\n",
       "\n",
       "Transformations to AST are applied by a series of transformers.\n",
       "\n",
       "        shell.transform_ast, shell.ast_transformers\n",
       "\n",
       "#### Eval\n",
       "\n",
       "The `shell` run the body of the [Abstract Syntax Tree] and\n",
       "\n",
       "        shell.run_ast_nodes, (\n",
       "\n",
       "#### Print\n",
       "\n",
       "formats any node meeting the criteria for the ast node interactivity. Typically, the last expression is shown.\n",
       "\n",
       "        ),shell.ast_node_interactivity, shell.display_formatter.format\n",
       "\n",
       "`IPython` triggers events when the REPL ends.\n",
       "\n",
       "        shell.events.callbacks.get('post_run_cell'), shell.events.callbacks.get('post_execute')\n",
       "\n",
       "#### Loop\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "{{load(pidgy.tests.test_repl)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "toc-hr-collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### [<code>[source]</code>](pidgy/tangle.ipynb)Tangling [Markdown] to [Python]\n",
       "\n",
       "\n",
       "\n",
       "The `pidgyTransformer` using the existing `IPython.core.inputtransformer2.TransformerManager` to configure the [Markdown] language features, and it is the public API for manipulating `pidgy` strings.  It implements the heuristics applied create predictable [Python] from [Markdown]\n",
       "\n",
       "\n",
       "    class pidgyTransformer(IPython.core.inputtransformer2.TransformerManager, base.Extension):\n",
       "        def pidgy_transform(self, cell: str) -> str: \n",
       "            return self.tokenizer.untokenize(self.tokenizer.parse(''.join(cell)))\n",
       "        \n",
       "        def transform_cell(self, cell: str) -> str:\n",
       "            return super().transform_cell(self.pidgy_transform(cell))\n",
       "        transform = transform_cell\n",
       "        \n",
       "        def __init__(self, *args, **kwargs):\n",
       "            super().__init__(*args, **kwargs)\n",
       "            self.tokenizer = Tokenizer()\n",
       "\n",
       "        def pidgy_magic(self, *text): \n",
       "            return IPython.display.Code(self.pidgy_transform(''.join(text)), language='python')\n",
       "\n",
       "\n",
       "#### The translation process\n",
       "\n",
       "A convenient considerations when tangling pidgy documents is that we are only concerned with the relative placements of block code objects relative the `not \"code\"` blocks.  `pidgy` customizes `mistune` language features for the purposes of a [Literate Computing] experience. The conversion to [Python] uses:\n",
       "1. lexical analysis to tokenize the markdown.\n",
       "2. the token are normalized to block `\"code\" and not \"code\"` objects.\n",
       "3. the tokens are translated to a string using heuristics that maintain line numbers between the representations.\n",
       "\n",
       "##### Block level lexical analysis.\n",
       "\n",
       "The block lexer converts a string in tokens that represent blocks of markdown in a text.  `pidgy` establishes a modified mistune block lexer that patches some needed features. It includes `doctest` syntax as a language feature. `doctest` are tested interactively, but they are consider `not \"code\"` objects in the [Markdown] to [Python] translation.  `doctest` is added because it is a common documentation approach in [Python], it is an example of [Literate Programming].\n",
       "\n",
       "<details><summary><code>BlockLexer</code></summary>\n",
       "\n",
       "\n",
       "    class BlockLexer(markdown.BlockLexer, util.ContextDepth):\n",
       "        class grammar_class(markdown.BlockGrammar):\n",
       "            doctest = doctest.DocTestParser._EXAMPLE_RE\n",
       "            block_code = re.compile(r'^((?!\\s+>>>\\s) {4}[^\\n]+\\n*)+')\n",
       "            default_rules = \"newline hrule block_code fences heading nptable lheading block_quote list_block def_links def_footnotes table paragraph text\".split()\n",
       "\n",
       "        def parse_doctest(self, m): self.tokens.append({'type': 'paragraph', 'text': m.group(0)})\n",
       "\n",
       "        def parse_fences(self, m):\n",
       "            if m.group(2): self.tokens.append({'type': 'paragraph', 'text': m.group(0)})\n",
       "            else: super().parse_fences(m)\n",
       "\n",
       "        def parse_hrule(self, m): self.tokens.append(dict(type='hrule', text=m.group(0)))\n",
       "            \n",
       "        def parse_def_links(self, m):\n",
       "            super().parse_def_links(m)\n",
       "            self.tokens.append(dict(type='def_link', text=m.group(0)))\n",
       "            \n",
       "        def parse(self, text: str, default_rules=None, normalize=True) -> typing.List[dict]:\n",
       "            if not self.depth: self.tokens = []\n",
       "            with self: tokens = super().parse(util.whiten(text), default_rules)\n",
       "            if normalize and not self.depth: tokens = normalizer(text, tokens)\n",
       "            return tokens\n",
       "        \n",
       "        depth = 0\n",
       "        def __enter__(self): self.depth += 1\n",
       "        def __exit__(self, *e): self.depth -= 1\n",
       "\n",
       "\n",
       "\n",
       "<!--\n",
       "    \n",
       "    for x in \"default_rules footnote_rules list_rules\".split():\n",
       "        setattr(BlockLexer, x, list(getattr(BlockLexer, x)))\n",
       "        getattr(BlockLexer, x).insert(getattr(BlockLexer, x).index('block_code'), 'doctest')\n",
       "        if 'block_html' in getattr(BlockLexer, x):\n",
       "            getattr(BlockLexer, x).pop(getattr(BlockLexer, x).index('block_html'))\n",
       "\n",
       "\n",
       "-->\n",
       "\n",
       "\n",
       "</details>\n",
       "\n",
       "##### Normalizing the tokens\n",
       "\n",
       "This extra step flattens the canonical mistune token representation to the collection of `\"code\" and not \"code\"` tokens.\n",
       "\n",
       "<details><summary><code>normalizer</code></summary>\n",
       "\n",
       "\n",
       "    def normalizer(text, tokens):\n",
       "        \"\"\"Combine non-code tokens into contiguous blocks.\"\"\"\n",
       "        compacted = []\n",
       "        while tokens:\n",
       "            token = tokens.pop(0)\n",
       "            if 'text' not in token: continue\n",
       "            else: \n",
       "                if not token['text'].strip(): continue\n",
       "                block, body = token['text'].splitlines(), \"\"\n",
       "            while block:\n",
       "                line = block.pop(0)\n",
       "                if line:\n",
       "                    before, line, text = text.partition(line)\n",
       "                    body += before + line\n",
       "            if token['type']=='code':\n",
       "                compacted.append({'type': 'code', 'lang': None, 'text': body})\n",
       "            else:\n",
       "                if compacted and compacted[-1]['type'] == 'paragraph':\n",
       "                    compacted[-1]['text'] += body\n",
       "                else: compacted.append({'type': 'paragraph', 'text': body})\n",
       "        if compacted and compacted[-1]['type'] == 'paragraph':\n",
       "            compacted[-1]['text'] += text\n",
       "        elif text.strip():\n",
       "            compacted.append({'type': 'paragraph', 'text': text})\n",
       "        # Deal with front matter\n",
       "        if compacted[0]['text'].startswith('---\\n') and '\\n---' in compacted[0]['text'][4:]:\n",
       "            token = compacted.pop(0)\n",
       "            front_matter, sep, paragraph = token['text'][4:].partition('---')\n",
       "            compacted = [{'type': 'front_matter', 'text': F\"\\n{front_matter}\"},\n",
       "                        {'type': 'paragraph', 'text': paragraph}] + compacted\n",
       "        return compacted\n",
       "\n",
       "\n",
       "</details>\n",
       "\n",
       "##### Flattening the tokens to a [Python] string.\n",
       "\n",
       "The tokenizer controls the translation of markdown strings to python strings.  Our major constraint is that the Markdown input should retain line numbers.\n",
       "\n",
       "<details><summary><code>Flatten</code></summary>\n",
       "\n",
       "\n",
       "    class Tokenizer(BlockLexer):\n",
       "        def untokenize(self, tokens: typing.List[dict], source: str = \"\"\"\"\"\", last: int =0) -> str:\n",
       "            INDENT = indent = util.base_indent(tokens) or 4\n",
       "            for i, token in enumerate(tokens):\n",
       "                object = token['text']\n",
       "                if token and token['type'] == 'code':\n",
       "                    if object.lstrip().startswith(FENCE):\n",
       "\n",
       "                        object = ''.join(''.join(object.partition(FENCE)[::2]).rpartition(FENCE)[::2])\n",
       "                        indent = INDENT + util.num_first_indent(object)\n",
       "                        object = textwrap.indent(object, INDENT*SPACE)\n",
       "\n",
       "                    if object.lstrip().startswith(MAGIC):  ...\n",
       "                    else: indent = util.num_last_indent(object)\n",
       "                elif token and token['type'] == 'front_matter': \n",
       "                    object = textwrap.indent(\n",
       "                        F\"locals().update(__import__('yaml').safe_load({util.quote(object)}))\\n\", indent*SPACE)\n",
       "\n",
       "                elif not object: ...\n",
       "                else:\n",
       "                    object = textwrap.indent(object, SPACE*max(indent-util.num_first_indent(object), 0))\n",
       "                    for next in tokens[i+1:]:\n",
       "                        if next['type'] == 'code':\n",
       "                            next = util.num_first_indent(next['text'])\n",
       "                            break\n",
       "                    else: next = indent       \n",
       "                    Δ = max(next-indent, 0)\n",
       "\n",
       "                    if not Δ and source.rstrip().rstrip(CONTINUATION).endswith(COLON): \n",
       "                        Δ += 4\n",
       "\n",
       "                    spaces = util.num_whitespace(object)\n",
       "                    \"what if the spaces are ling enough\"\n",
       "                    object = object[:spaces] + Δ*SPACE+ object[spaces:]\n",
       "                    if not source.rstrip().rstrip(CONTINUATION).endswith(QUOTES): \n",
       "                        object = util.quote(object)\n",
       "                source += object\n",
       "\n",
       "            # add a semicolon to the source if the last block is code.\n",
       "            for token in reversed(tokens):\n",
       "                if token['text'].strip():\n",
       "                    if token['type'] != 'code': \n",
       "                        source = source.rstrip() + SEMI\n",
       "                    break\n",
       "\n",
       "            return source\n",
       "\n",
       "\n",
       "</details>\n",
       "\n",
       "##### Normalizing the tokens\n",
       "\n",
       "This step may be superfluous, but it assisted in considering the logic necessary to compose the resulting python.  This extra step flattens the canonical mistune token representation is reduced to one of `\"paragraph code front_matter\"` tokens.\n",
       "\n",
       "</details>\n",
       "\n",
       "<details><summary>Utility functions for the tangle module</summary>\n",
       "\n",
       "\n",
       "    def normalizer(text: str, tokens: typing.List[dict]):\n",
       "        \"\"\"Combine non-code tokens into contiguous blocks.\"\"\"\n",
       "        compacted = []\n",
       "        while tokens:\n",
       "            token = tokens.pop(0)\n",
       "            if 'text' not in token: continue\n",
       "            else: \n",
       "                if not token['text'].strip(): continue\n",
       "                block, body = token['text'].splitlines(), \"\"\n",
       "            while block:\n",
       "                line = block.pop(0)\n",
       "                if line:\n",
       "                    before, line, text = text.partition(line)\n",
       "                    body += before + line\n",
       "            if token['type']=='code':\n",
       "                compacted.append({'type': 'code', 'lang': None, 'text': body})\n",
       "            else:\n",
       "                if compacted and compacted[-1]['type'] == 'paragraph':\n",
       "                    compacted[-1]['text'] += body\n",
       "                else: compacted.append({'type': 'paragraph', 'text': body})\n",
       "        if compacted and compacted[-1]['type'] == 'paragraph':\n",
       "            compacted[-1]['text'] += text\n",
       "        elif text.strip():\n",
       "            compacted.append({'type': 'paragraph', 'text': text})\n",
       "        \n",
       "        if compacted[0]['text'].startswith('---\\n') and '\\n---' in compacted[0]['text'][4:]:\n",
       "            token = compacted.pop(0)\n",
       "            front_matter, sep, paragraph = token['text'][4:].partition('---')\n",
       "            compacted = [{'type': 'front_matter', 'text': F\"\\n{front_matter}\"},\n",
       "                        {'type': 'paragraph', 'text': paragraph}] + compacted\n",
       "        return compacted\n",
       "\n",
       "\n",
       "</details>\n",
       "\n",
       "\n",
       "    def load_ipython_extension(shell):\n",
       "        shell.tangle = pidgyTransformer().register(shell)\n",
       "    \n",
       "    def unload_ipython_extension(shell):\n",
       "        if hasattr(shell, 'tangle'): shell.tangle.unregister(shell)\n",
       "    \n",
       "    (FENCE, CONTINUATION, SEMI, COLON, MAGIC, DOCTEST), QUOTES, SPACE ='``` \\\\ ; : %% >>>'.split(), ('\"\"\"', \"'''\"), ' '\n",
       "    WHITESPACE = re.compile('^\\s*', re.MULTILINE)\n",
       "\n",
       "    def unload_ipython_extension(shell):\n",
       "        if hasattr(shell, 'tangle'): shell.tangle.unregister(shell)\n",
       "\n",
       "    (FENCE, CONTINUATION, SEMI, COLON, MAGIC, DOCTEST), QUOTES, SPACE ='``` \\\\ ; : %% >>>'.split(), ('\"\"\"', \"'''\"), ' '\n",
       "    WHITESPACE = re.compile('^\\s*', re.MULTILINE)\n",
       "\n",
       "\n",
       "\n",
       "<!--\n",
       "    \n",
       "    for x in \"default_rules footnote_rules list_rules\".split():\n",
       "        setattr(BlockLexer, x, list(getattr(BlockLexer, x)))\n",
       "        getattr(BlockLexer, x).insert(getattr(BlockLexer, x).index('block_code'), 'doctest')\n",
       "        if 'block_html' in getattr(BlockLexer, x):\n",
       "            getattr(BlockLexer, x).pop(getattr(BlockLexer, x).index('block_html'))\n",
       "\n",
       "\n",
       "-->\n",
       "\n",
       "\n",
       "</summary></details>\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "{{load(pidgy.tangle, 2)}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### [<code>[source]</code>](pidgy/loader.ipynb)Importing and reusing `pidgy` literature\n",
       "\n",
       "A constraint consistent across most programming languages is that\n",
       "programs are executed line-by-line without any\n",
       "statements or expressions. raising exceptions \n",
       "If literate programs have the computational quality that they __restart\n",
       "and run all__ the they should \n",
       "When `pidgy` programs have this quality they can <code>import</code> in [Python], they become importable essays or reports.\n",
       "\n",
       "\n",
       "    __all__ = 'pidgyLoader',; import pidgy, IPython, importnb\n",
       "\n",
       "\n",
       "The `pidgyLoader` customizes [Python]'s ability to discover \n",
       "[Markdown] and `pidgy` [Notebook]s have the composite `\".md.ipynb\"` extension.\n",
       "`importnb` provides a high level API for modifying how content\n",
       "[Python] imports different file types.\n",
       "\n",
       "`sys.meta_path and sys.path_hooks`\n",
       "\n",
       "\n",
       "    class pidgyLoader(importnb.Notebook): \n",
       "        extensions = \".py.md .md .md.ipynb\".split()\n",
       "\n",
       "\n",
       "`get_data` determines how a file is decoding from disk.  We use it to make an escape hatch for markdown files otherwise we are importing a notebook.\n",
       "\n",
       "\n",
       "    def get_data(self, path):\n",
       "        if self.path.endswith('.md'): return self.code(self.decode())\n",
       "        return super(pidgyLoader, self).get_data(path)\n",
       "\n",
       "\n",
       "The `code` method tangles the [Markdown] to [Python] before compiling to an [Abstract Syntax Tree].\n",
       "\n",
       "\n",
       "    def code(self, str): \n",
       "        with importnb.Notebook():\n",
       "            try: from . import tangle, extras\n",
       "            except: import tangle, extras\n",
       "        return ''.join(extras.demojize(''.join(tangle.pidgyTransformer().transform_cell(str))))\n",
       "\n",
       "\n",
       "The `visit` method allows custom [Abstract Syntax Tree] transformations to be applied.\n",
       "\n",
       "\n",
       "    def visit(self, node):\n",
       "        with importnb.Notebook():\n",
       "            try: from . import extras\n",
       "            except: import extras\n",
       "        return extras.ExtraSyntax().visit(node)\n",
       "\n",
       "\n",
       "Attach these methods to the `pidgy` loader.\n",
       "\n",
       "\n",
       "    pidgyLoader.code, pidgyLoader.visit = code, visit\n",
       "    pidgyLoader.get_source = pidgyLoader.get_data = get_data\n",
       "    \n",
       "Collect all of the functions defined into the `pidgyLoader`.\n",
       "\n",
       "\n",
       "The `pidgy` `loader` configures how [Python] discovers modules when they are\n",
       "imported.\n",
       "Usually the loader is used as a content manager and in this case we hold the enter \n",
       "the context, but do not leave it until `unload_ipython_extension` is executed.\n",
       "\n",
       "-->\n",
       "\n",
       "\n",
       "    def load_ipython_extension(shell, loader=pidgyLoader):\n",
       "        setattr(shell, 'loaders', getattr(shell, 'loaders', {}))\n",
       "        shell.loaders[pidgyLoader] = loader(position=-1)\n",
       "        shell.loaders[pidgyLoader].__enter__()\n",
       "\n",
       "\n",
       "<!--\n",
       "\n",
       "\n",
       "<!--\n",
       "    \n",
       "    def unload_ipython_extension(shell, loader=pidgyLoader): \n",
       "        loader = shell.loaders.pop(pidgyLoader)\n",
       "        loader and loader.__exit__(None, None, None)\n",
       "\n",
       "-->\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "{{load(pidgy.loader, 2)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### [<code>[source]</code>](pidgy/pytest_config/readme.md)Literature as the test\n",
       "\n",
       "    import pidgy, pytest, nbval, doctest, importnb.utils.pytest_importnb\n",
       "\n",
       "Literate documents can be motivated by the need to test a concept. In a fact, a common\n",
       "use case of notebooks is that they interactively test units of thought. Often the thought\n",
       "of reusability is an after thought.\n",
       "\n",
       "`pidgy` documents are meant to be treated as test objects. In fact, the `pidgy` test suite\n",
       "executed by `pytest` through [Github Actions][actions] uses `pidgy` notebooks (ie. documents with the `\".md\" or \".md.ipynb\"` extension). `pidgy` supplies its own `pytest` extensions, and it uses [`nbval`][nbval] and the `pytest`\"--doctest-modules\"`flag. With these conditions we discover pytest conventions, unitests, doctests, and options cell input output validated. Ultimately,`pidgy` documents may represent units of literate that double as formal test objects.\n",
       "\n",
       "The document accessed by the `\"pytest11\"` console_script and includes the extension with a pytest runner.\n",
       "\n",
       "    class pidgyModule(importnb.utils.pytest_importnb.NotebookModule):\n",
       "\n",
       "The `pidgyModule` derives from an existing `pytest` extension that extracts formal tests from `notebook`s\n",
       "as if they were regular python files. We'll use the `pidgy.pidgyLoader` to load Markdown-forward documents\n",
       "as python objects.\n",
       "\n",
       "        loader = pidgy.pidgyLoader\n",
       "\n",
       "    class pidgyTests(importnb.utils.pytest_importnb.NotebookTests):\n",
       "\n",
       "`pidgyTests` makes sure to include the alternative source formats to tangle to python executions.\n",
       "\n",
       "        modules = pidgyModule,\n",
       "\n",
       "[nbval]: https://github.com/computationalmodelling/nbval/ \"The pidgy kernel works directly with `nbval`.\"\n",
       "[actions]: https://github.com/deathbeds/pidgy/runs/478462971\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "{{load(pidgy.pytest_config.readme, 2)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### [<code>[source]</code>](pidgy/readme.md)`\"readme.md\"` is a good name for a file.\n",
       "\n",
       "> [**Eat Me, Drink Me, Read Me.**][readme history]\n",
       "\n",
       "In `pidgy`, the `\"readme.md\"` is treated as the description and implementation\n",
       "of the `__main__` program. The code below outlines the `pidgy` command line\n",
       "application to reuse literate `pidgy` documents in `markdown` and `notebook`\n",
       "files. It outlines how static `pidgy` documents may be reused outside of the\n",
       "interactive context.\n",
       "\n",
       "<!--excerpt-->\n",
       "\n",
       "    ...\n",
       "\n",
       "<!--\n",
       "\n",
       "    import click, IPython, pidgy, nbconvert, pathlib, re\n",
       "\n",
       "-->\n",
       "\n",
       "    @click.group()\n",
       "    def application()->None:\n",
       "\n",
       "The `pidgy` `application` will group together a few commands that can view,\n",
       "execute, and test pidgy documents.\n",
       "\n",
       "<!---->\n",
       "\n",
       "#### `\"pidgy run\"` literature as code\n",
       "\n",
       "    @application.command(context_settings=dict(allow_extra_args=True))\n",
       "    @click.option('--verbose/--quiet', default=True)\n",
       "    @click.argument('ref', type=click.STRING)\n",
       "    @click.pass_context\n",
       "    def run(ctx, ref, verbose):\n",
       "\n",
       "`pidgy` `run` makes it possible to execute `pidgy` documents as programs, and\n",
       "view their pubished results.\n",
       "\n",
       "        import pidgy, importnb, runpy, sys, importlib, jinja2\n",
       "        comment = re.compile(r'(?s:<!--.*?-->)')\n",
       "        absolute = str(pathlib.Path().absolute())\n",
       "        sys.path = ['.'] + sys.path\n",
       "        with pidgy.pidgyLoader(main=True), importnb.Notebook(main=True):\n",
       "            click.echo(F\"Running {ref}.\")\n",
       "            sys.argv, argv = [ref] + ctx.args, sys.argv\n",
       "            try:\n",
       "                if pathlib.Path(ref).exists():\n",
       "                    for ext in \".py .ipynb .md\".split(): ref = ref[:-len(ext)] if ref[-len(ext):] == ext else ref\n",
       "                if ref in sys.modules:\n",
       "                    with pidgy.pidgyLoader(): # cant reload main\n",
       "                        object = importlib.reload(importlib.import_module(ref))\n",
       "                else: object = importlib.import_module(ref)\n",
       "                if verbose:\n",
       "                    md = (nbconvert.get_exporter('markdown')(\n",
       "                        exclude_output=object.__file__.endswith('.md.ipynb')).from_filename(object.__file__)[0]\n",
       "                            if object.__file__.endswith('.ipynb')\n",
       "                            else pathlib.Path(object.__file__).read_text())\n",
       "                    md = re.sub(comment, '', md)\n",
       "                    click.echo(\n",
       "                        jinja2.Template(md).render(vars(object)))\n",
       "            finally: sys.argv = argv\n",
       "\n",
       "<!---->\n",
       "\n",
       "#### Test `pidgy` documents in pytest.\n",
       "\n",
       "    @application.command(context_settings=dict(allow_extra_args=True))\n",
       "    @click.argument('files', nargs=-1, type=click.STRING)\n",
       "    @click.pass_context\n",
       "    def test(ctx, files):\n",
       "\n",
       "Formally test markdown documents, notebooks, and python files.\n",
       "\n",
       "         import pytest\n",
       "         pytest.main(ctx.args+['--doctest-modules', '--disable-pytest-warnings']+list(files))\n",
       "\n",
       "<!---->\n",
       "\n",
       "#### Install `pidgy` as a known kernel.\n",
       "\n",
       "    @application.group()\n",
       "    def kernel():\n",
       "\n",
       "`pidgy` is mainly designed to improve the interactive experience of creating\n",
       "literature in computational notebooks.\n",
       "\n",
       "<!---->\n",
       "\n",
       "    @kernel.command()\n",
       "    def install(user=False, replace=None, prefix=None):\n",
       "\n",
       "`install` the pidgy kernel.\n",
       "\n",
       "        manager = __import__('jupyter_client').kernelspec.KernelSpecManager()\n",
       "        path = str((pathlib.Path(__file__).parent / 'kernelspec').absolute())\n",
       "        try:\n",
       "            dest = manager.install_kernel_spec(path, 'pidgy')\n",
       "        except:\n",
       "            click.echo(F\"System install was unsuccessful. Attempting to install the pidgy kernel to the user.\")\n",
       "            dest = manager.install_kernel_spec(path, 'pidgy', True)\n",
       "        click.echo(F\"The pidgy kernel was install in {dest}\")\n",
       "\n",
       "<!--\n",
       "\n",
       "    @kernel.command()\n",
       "    def uninstall(user=True, replace=None, prefix=None):\n",
       "\n",
       "`uninstall` the kernel.\n",
       "\n",
       "        import jupyter_client\n",
       "        jupyter_client.kernelspec.KernelSpecManager().remove_kernel_spec('pidgy')\n",
       "        click.echo(F\"The pidgy kernel was removed.\")\n",
       "\n",
       "\n",
       "    @kernel.command()\n",
       "    @click.option('-f')\n",
       "    def start(user=True, replace=None, prefix=None, f=None):\n",
       "\n",
       "Launch a `pidgy` kernel applications.\n",
       "\n",
       "        import ipykernel.kernelapp\n",
       "        with pidgy.pidgyLoader():\n",
       "            from . import kernel\n",
       "        ipykernel.kernelapp.IPKernelApp.launch_instance(\n",
       "            kernel_class=kernel.pidgyKernel)\n",
       "    ...\n",
       "\n",
       "-->\n",
       "\n",
       "[art of the readme]: https://github.com/noffle/art-of-readme\n",
       "[readme history]: https://medium.com/@NSomar/readme-md-history-and-components-a365aff07f10\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "{{load(pidgy.readme, 2)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "toc-hr-collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### [<code>[source]</code>](pidgy/kernel.md)Configuring the `pidgy` shell and kernel architecture.\n",
       "\n",
       "![](https://jupyter.readthedocs.io/en/latest/_images/other_kernels.png)\n",
       "\n",
       "Interactive programming in `pidgy` documents is accessed using the polyglot\n",
       "[Jupyter] kernel architecture. In fact, the provenance the [Jupyter]\n",
       "name is a combination the native kernel architectures for\n",
       "[ju~~lia~~][julia], [pyt~~hon~~][python], and [r]. [Jupyter]'s\n",
       "generalization of the kernel/shell interface allows\n",
       "over 100 languages to be used in `notebook and jupyterlab`.\n",
       "It is possible to define prescribe wrapper kernels around existing\n",
       "methods; this is the appraoach that `pidgy` takes\n",
       "\n",
       "> A kernel provides programming language support in Jupyter. IPython is the default kernel. Additional kernels include R, Julia, and many more.\n",
       ">\n",
       "> > - [`jupyter` kernel definition](https://jupyter.readthedocs.io/en/latest/glossary.html#term-kernel)\n",
       "\n",
       "`pidgy` is not not a native kernel. It is a wrapper kernel around the\n",
       "existing `ipykernel and IPython.InteractiveShell` configurables.\n",
       "`IPython` adds extra syntax to python that simulate literate programming\n",
       "macros.\n",
       "\n",
       "<!--\n",
       "\n",
       "    import jupyter_client, IPython, ipykernel.ipkernel, ipykernel.kernelapp, pidgy, traitlets, pidgy, traitlets, ipykernel.kernelspec, ipykernel.zmqshell, pathlib, traitlets\n",
       "\n",
       "-->\n",
       "\n",
       "The shell is the application either jupyterlab or jupyter notebook, the kernel\n",
       "determines the programming language. Below we design a just jupyter kernel that\n",
       "can be installed using\n",
       "\n",
       "- What is the advantage of installing the kernel and how to do it.\n",
       "\n",
       "```bash\n",
       "pidgy kernel install\n",
       "```\n",
       "\n",
       "#### Configure the `pidgy` shell.\n",
       "\n",
       "    class pidgyInteractiveShell(ipykernel.zmqshell.ZMQInteractiveShell):\n",
       "\n",
       "Configure a native `pidgy` `IPython.InteractiveShell`\n",
       "\n",
       "        loaders = traitlets.Dict(allow_none=True)\n",
       "        weave = traitlets.Any(allow_none=True)\n",
       "        tangle = ipykernel.zmqshell.ZMQInteractiveShell.input_transformer_manager\n",
       "        extras = traitlets.Any(allow_none=True)\n",
       "        testing = traitlets.Any(allow_none=True)\n",
       "        enable_html_pager = traitlets.Bool(True)\n",
       "\n",
       "`pidgyInteractiveShell.enable_html_pager` is necessary to see rich displays in\n",
       "the inspector.\n",
       "\n",
       "        def __init__(self,*args, **kwargs):\n",
       "            super().__init__(*args, **kwargs)\n",
       "            with pidgy.pidgyLoader():\n",
       "                from .extension import load_ipython_extension\n",
       "            load_ipython_extension(self)\n",
       "\n",
       "#### Configure the `pidgy` kernel.\n",
       "\n",
       "    class pidgyKernel(ipykernel.ipkernel.IPythonKernel):\n",
       "        shell_class = traitlets.Type(pidgyInteractiveShell)\n",
       "        _last_parent = traitlets.Dict()\n",
       "\n",
       "        def init_metadata(self, parent):\n",
       "            self._last_parent = parent\n",
       "            return super().init_metadata(parent)\n",
       "\n",
       "\n",
       "        def do_inspect(self, code, cursor_pos, detail_level=0):\n",
       "\n",
       "<details><summary>Customizing the Jupyter inspector behavior for literate computing</summary><p>\n",
       "When we have access to the kernel class it is possible to customize\n",
       "a number of interactive shell features.   The do inspect function\n",
       "adds some features to `jupyter`'s  inspection behavior when working in \n",
       "`pidgy`.\n",
       "</p><pre></code>\n",
       "\n",
       "            object = {'found': False}\n",
       "            if code[:cursor_pos][-3:] == '!!!':\n",
       "                object = {'found': True, 'data': {'text/markdown': self.shell.weave.format_markdown(code[:cursor_pos-3]+code[cursor_pos:])}}\n",
       "            else:\n",
       "                try:\n",
       "                    object = super().do_inspect(code, cursor_pos, detail_level=0)\n",
       "                except: ...\n",
       "\n",
       "            if not object['found']:\n",
       "\n",
       "Simulate finding an object and return a preview of the markdown.\n",
       "\n",
       "                object['found'] = True\n",
       "                line, offset = IPython.utils.tokenutil.line_at_cursor(code, cursor_pos)\n",
       "                lead = code[:cursor_pos]\n",
       "                col = cursor_pos - offset\n",
       "\n",
       "\n",
       "                code = F\"\"\"<code>·L{\n",
       "                    len(lead.splitlines()) + int(not(col))\n",
       "                },C{col + 1}</code><br/>\\n\\n\"\"\" + code[:cursor_pos]+'·'+('' if col else '<br/>\\n')+code[cursor_pos:]\n",
       "\n",
       "                object['data'] = {'text/markdown': code}\n",
       "\n",
       "We include the line number and cursor position to enrich the connection between\n",
       "the inspector and the source code displayed on another part of the screen.\n",
       "\n",
       "            return object\n",
       "        ...\n",
       "\n",
       "</details>\n",
       "\n",
       "#### `pidgy`-like interfaces in other languages.\n",
       "\n",
       "[julia]: #\n",
       "[r]: #\n",
       "[python]: #\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "{{load(pidgy.kernel, 2)}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### [<code>[source]</code>](pidgy/extras.ipynb)Extra langauge features of `pidgy`\n",
       "\n",
       "`pidgy` experiments extra language features for python, using the same system\n",
       "that IPython uses to add features like line and cell magics.\n",
       "\n",
       "<!--\n",
       "\n",
       "\n",
       "    import IPython, typing as τ, mistune as markdown, IPython, importnb as _import_, textwrap, ast, doctest, typing, re\n",
       "    import dataclasses, ast, pidgy\n",
       "    with pidgy.pidgyLoader(lazy=True):\n",
       "        try: from . import events\n",
       "        except: import events\n",
       "\n",
       "\n",
       "-->\n",
       "\n",
       "##### naming variables with gestures.\n",
       "\n",
       "We know naming is hard, there is no point focusing on it. `pidgy` allows authors\n",
       "to use emojis as variables in python. They add extra color and expression to the narrative.\n",
       "\n",
       "\n",
       "    def demojize(lines, delimiters=('_', '_')):\n",
       "        str = ''.join(lines)\n",
       "        import tokenize, emoji, stringcase; tokens = []\n",
       "        try:\n",
       "            for token in list(tokenize.tokenize(\n",
       "                __import__('io').BytesIO(str.encode()).readline)):\n",
       "                if token.type == tokenize.ERRORTOKEN:\n",
       "                    string = emoji.demojize(token.string, delimiters=delimiters\n",
       "                                           ).replace('-', '_').replace(\"’\", \"_\")\n",
       "                    if tokens and tokens[-1].type == tokenize.NAME: tokens[-1] = tokenize.TokenInfo(tokens[-1].type, tokens[-1].string + string, tokens[-1].start, tokens[-1].end, tokens[-1].line)\n",
       "                    else: tokens.append(\n",
       "                        tokenize.TokenInfo(\n",
       "                            tokenize.NAME, string, token.start, token.end, token.line))\n",
       "                else: tokens.append(token)\n",
       "            return tokenize.untokenize(tokens).decode().splitlines(True)\n",
       "        except BaseException: raise SyntaxError(str)\n",
       "\n",
       "\n",
       "##### Top level return and yield statements.\n",
       "\n",
       "<!--\n",
       "\n",
       "\n",
       "    def unload_ipython_extension(shell):\n",
       "        shell.extras.unregister()\n",
       "\n",
       "\n",
       "-->\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "{{load(pidgy.extras, 3)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "toc-hr-collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### [<code>[source]</code>](pidgy/weave.md)Weaving cells in pidgin programs\n",
       "\n",
       "<!--\n",
       "\n",
       "    import dataclasses, IPython, nbconvert as convert, jinja2\n",
       "    exporter = convert.exporters.TemplateExporter()\n",
       "    try:\n",
       "        from . import base, util\n",
       "    except:\n",
       "        import base, util\n",
       "\n",
       "\n",
       "-->\n",
       "\n",
       "pidgin programming is an incremental approach to documents.\n",
       "\n",
       "    @dataclasses.dataclass\n",
       "    class Weave(base.Extension):\n",
       "        environment: jinja2.Environment = dataclasses.field(default=exporter.environment)\n",
       "\n",
       "        def format_markdown(self, text):\n",
       "            lines = text.splitlines() or ['']\n",
       "            if not lines[0].strip(): return F\"\"\"<!--\\n{text}\\n\\n-->\"\"\"\n",
       "            try:\n",
       "                template = exporter.environment.from_string(text, globals=getattr(self.shell, 'user_ns', {}))\n",
       "                text = template.render()\n",
       "            except BaseException as Exception:\n",
       "                self.shell.showtraceback((type(Exception), Exception, Exception.__traceback__))\n",
       "            return text\n",
       "\n",
       "        def format_metadata(self):\n",
       "            parent = getattr(self.shell.kernel, '_last_parent', {})\n",
       "            return {}\n",
       "\n",
       "        def _update_filters(self):\n",
       "            self.environment.filters.update({\n",
       "                k: v for k, v in getattr(self.shell, 'user_ns', {}).items() if callable(v) and k not in self.environment.filters})\n",
       "\n",
       "\n",
       "        def post_run_cell(self, result):\n",
       "            text = util.strip_front_matter(result.info.raw_cell)\n",
       "            IPython.display.display(IPython.display.Markdown(self.format_markdown(text), metadata=self.format_metadata()))\n",
       "            return result\n",
       "            \n",
       "    def load_ipython_extension(shell):\n",
       "        shell.weave = Weave(shell=shell)\n",
       "        shell.weave.register()\n",
       "\n",
       "\n",
       "\n",
       "    def unload_ipython_extension(shell):\n",
       "        try:\n",
       "            shell.weave.unregister()\n",
       "        except:...\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "{{load(pidgy.weave, 2)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "toc-hr-collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### [<code>[source]</code>](pidgy/testing.md)Interactive testing of literate programs\n",
       "\n",
       "Testing is something we added because of the application of notebooks as test units.\n",
       "\n",
       "A primary use case of notebooks is to test ideas. Typically this in informally using\n",
       "manual validation to qualify the efficacy of narrative and code. To ensure testable literate documents\n",
       "we formally test code incrementally during interactive computing.\n",
       "\n",
       "<!--\n",
       "\n",
       "    import unittest, doctest, textwrap, dataclasses, IPython, re, pidgy, sys, typing, types, contextlib, ast, inspect\n",
       "    with pidgy.pidgyLoader(lazy=True):\n",
       "        try: from . import events\n",
       "        except: import events\n",
       "\n",
       "-->\n",
       "\n",
       "    def make_test_suite(*objects: typing.Union[\n",
       "        unittest.TestCase, types.FunctionType, str\n",
       "    ], vars, name) -> unittest.TestSuite:\n",
       "\n",
       "The interactive testing suite execute `doctest and unittest` conventions\n",
       "for a flexible interface to verifying the computational qualities of literate programs.\n",
       "\n",
       "        suite, doctest_suite = unittest.TestSuite(), doctest.DocTestSuite()\n",
       "        suite.addTest(doctest_suite)\n",
       "        for object in objects:\n",
       "            if isinstance(object, type) and issubclass(object, unittest.TestCase):\n",
       "                suite.addTest(unittest.defaultTestLoader.loadTestsFromTestCase(object))\n",
       "            elif isinstance(object, str):\n",
       "                doctest_suite.addTest(doctest.DocTestCase(\n",
       "                doctest.DocTestParser().get_doctest(object, vars, name, name, 1), doctest.ELLIPSIS))\n",
       "                doctest_suite.addTest(doctest.DocTestCase(\n",
       "                InlineDoctestParser().get_doctest(object, vars, name, name, 1), checker=NullOutputCheck))\n",
       "            elif inspect.isfunction(object):\n",
       "                suite.addTest(unittest.FunctionTestCase(object))\n",
       "        return suite\n",
       "\n",
       "    @dataclasses.dataclass\n",
       "    class Testing(events.Events):\n",
       "\n",
       "The `Testing` class executes the test suite each time a cell is executed.\n",
       "\n",
       "        function_pattern: str = 'test_'\n",
       "        def post_run_cell(self, result):\n",
       "            globs, filename = self.shell.user_ns, F\"In[{self.shell.last_execution_result.execution_count}]\"\n",
       "\n",
       "            if not (result.error_before_exec or result.error_in_exec):\n",
       "                with ipython_compiler(self.shell):\n",
       "                    definitions = [self.shell.user_ns[x] for x in getattr(self.shell.metadata, 'definitions', [])\n",
       "                        if x.startswith(self.function_pattern) or\n",
       "                        (isinstance(self.shell.user_ns[x], type)\n",
       "                         and issubclass(self.shell.user_ns[x], unittest.TestCase))\n",
       "                    ]\n",
       "                    result = self.run(make_test_suite(result.info.raw_cell, *definitions, vars=self.shell.user_ns, name=filename), result)\n",
       "\n",
       "\n",
       "        def run(self, suite: unittest.TestCase, cell) -> unittest.TestResult:\n",
       "            result = unittest.TestResult(); suite.run(result)\n",
       "            if result.failures:\n",
       "                msg = '\\n'.join(msg for text, msg in result.failures)\n",
       "                msg = re.sub(re.compile(\"<ipython-input-[0-9]+-\\S+>\"), F'In[{cell.execution_count}]', clean_doctest_traceback(msg))\n",
       "                sys.stderr.writelines((str(result) + '\\n' + msg).splitlines(True))\n",
       "                return result\n",
       "\n",
       "    @contextlib.contextmanager\n",
       "    def ipython_compiler(shell):\n",
       "\n",
       "We'll have to replace how `doctest` compiles code with the `IPython` machinery.\n",
       "\n",
       "        def compiler(input, filename, symbol, *args, **kwargs):\n",
       "            nonlocal shell\n",
       "            return shell.compile(\n",
       "                ast.Interactive(\n",
       "                    body=shell.transform_ast(\n",
       "                    shell.compile.ast_parse(shell.transform_cell(textwrap.indent(input, ' '*4)))\n",
       "                ).body),\n",
       "                F\"In[{shell.last_execution_result.execution_count}]\",\n",
       "                \"single\",\n",
       "            )\n",
       "\n",
       "        yield setattr(doctest, \"compile\", compiler)\n",
       "        doctest.compile = compile\n",
       "\n",
       "    def clean_doctest_traceback(str, *lines):\n",
       "        str = re.sub(re.compile(\"\"\"\\n\\s+File [\\s\\S]+, line [0-9]+, in runTest\\s+raise[\\s\\S]+\\([\\s\\S]+\\)\\n?\"\"\"), '\\n', str)\n",
       "        return re.sub(re.compile(\"Traceback \\(most recent call last\\):\\n\"), '', str)\n",
       "\n",
       "<details><summary>Utilities for the testing module.</summary>\n",
       "    \n",
       "    class NullOutputCheck(doctest.OutputChecker):\n",
       "        def check_output(self, *e): return True\n",
       "\n",
       "    class InlineDoctestParser(doctest.DocTestParser):\n",
       "        _EXAMPLE_RE = re.compile(r'`(?P<indent>\\s{0})'\n",
       "    r'(?P<source>[^`].*?)'\n",
       "    r'`')\n",
       "        def _parse_example(self, m, name, lineno): return m.group('source'), None, \"...\", None\n",
       "\n",
       "\n",
       "    def load_ipython_extension(shell):\n",
       "        shell.testing = Testing(shell=shell).register()\n",
       "\n",
       "    def unload_ipython_extension(shell):\n",
       "        shell.testing.unregister()\n",
       "\n",
       "</details>\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "{{load(pidgy.testing, 2)}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### [<code>[source]</code>](pidgy/metadata.md)Capturing metadata during the interactive compute process\n",
       "\n",
       "To an organization, human compute time bears an important cost\n",
       "and programming represents a small part of that cycle.\n",
       "\n",
       "    def load_ipython_extension(shell):\n",
       "\n",
       "The `metadata` module assists in collecting metadata about the interactive compute process.\n",
       "It appends the metadata atrribute to the shell.\n",
       "\n",
       "        shell.metadata = Metadata(shell=shell).register()\n",
       "\n",
       "<!--\n",
       "\n",
       "    import dataclasses, ast, pidgy\n",
       "    with pidgy.pidgyLoader(lazy=True):\n",
       "        try: from . import events\n",
       "        except: import events\n",
       "\n",
       "-->\n",
       "\n",
       "    @dataclasses.dataclass\n",
       "    class Metadata(events.Events, ast.NodeTransformer):\n",
       "        definitions: list = dataclasses.field(default_factory=list)\n",
       "        def pre_execute(self):\n",
       "            self.definitions = []\n",
       "\n",
       "        def visit_FunctionDef(self, node):\n",
       "            self.definitions.append(node.name)\n",
       "            return node\n",
       "\n",
       "        visit_ClassDef = visit_FunctionDef\n",
       "\n",
       "<!--\n",
       "\n",
       "    def unload_ipython_extension(shell):\n",
       "        shell.metadata.unregister()\n",
       "\n",
       "-->\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "{{load(pidgy.metadata, 2)}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{{load('readme.md')}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Appendix\n",
       "\n",
       "[Python] files and notebooks typically represent appendix files."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Appendix\n",
    "\n",
    "[Python] files and notebooks typically represent appendix files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### `pidgy` base extension registration."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### `pidgy` base extension registration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.output_html .hll { background-color: #ffffcc }\n",
       ".output_html  { background: #f8f8f8; }\n",
       ".output_html .c { color: #408080; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #408080; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #408080; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #BC7A00 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #408080; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #408080; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .gr { color: #FF0000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #00A000 } /* Generic.Inserted */\n",
       ".output_html .go { color: #888888 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #7D9029 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #999999; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #D2413A; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #A0A000 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #BB6688 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">IPython</span><span class=\"o\">,</span> <span class=\"nn\">ast</span><span class=\"o\">,</span> <span class=\"nn\">dataclasses</span><span class=\"o\">,</span> <span class=\"nn\">functools</span><span class=\"o\">,</span> <span class=\"nn\">importnb</span>\n",
       "\n",
       "\n",
       "<span class=\"nd\">@dataclasses</span><span class=\"o\">.</span><span class=\"n\">dataclass</span>\n",
       "<span class=\"k\">class</span> <span class=\"nc\">Extension</span><span class=\"p\">:</span>\n",
       "    <span class=\"sd\">&quot;&quot;&quot;`Extension` is base class that simplifies loading and unloading IPython extensions. Each component of `pidgy` is an IPython extension are this work compacts some repetative practices.&quot;&quot;&quot;</span>\n",
       "\n",
       "    <span class=\"n\">_repl_events</span> <span class=\"o\">=</span> <span class=\"s2\">&quot;pre_execute pre_run_cell post_execute post_run_cell&quot;</span><span class=\"o\">.</span><span class=\"n\">split</span><span class=\"p\">()</span>\n",
       "    <span class=\"n\">shell</span><span class=\"p\">:</span> <span class=\"n\">IPython</span><span class=\"o\">.</span><span class=\"n\">InteractiveShell</span> <span class=\"o\">=</span> <span class=\"n\">dataclasses</span><span class=\"o\">.</span><span class=\"n\">field</span><span class=\"p\">(</span>\n",
       "        <span class=\"n\">default_factory</span><span class=\"o\">=</span><span class=\"n\">IPython</span><span class=\"o\">.</span><span class=\"n\">get_ipython</span>\n",
       "    <span class=\"p\">)</span>\n",
       "\n",
       "    <span class=\"k\">def</span> <span class=\"nf\">register</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">shell</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"p\">,</span> <span class=\"n\">method</span><span class=\"o\">=</span><span class=\"s2\">&quot;&quot;</span><span class=\"p\">):</span>\n",
       "        <span class=\"k\">if</span> <span class=\"n\">shell</span><span class=\"p\">:</span>\n",
       "            <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">shell</span> <span class=\"o\">=</span> <span class=\"n\">shell</span>\n",
       "        <span class=\"n\">register</span><span class=\"p\">,</span> <span class=\"n\">unregister</span> <span class=\"o\">=</span> <span class=\"ow\">not</span> <span class=\"nb\">bool</span><span class=\"p\">(</span><span class=\"n\">method</span><span class=\"p\">),</span> <span class=\"nb\">bool</span><span class=\"p\">(</span><span class=\"n\">method</span><span class=\"p\">)</span>\n",
       "        <span class=\"n\">shell</span> <span class=\"o\">=</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">shell</span>\n",
       "        <span class=\"k\">for</span> <span class=\"n\">event</span> <span class=\"ow\">in</span> <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">_repl_events</span><span class=\"p\">:</span>\n",
       "            <span class=\"n\">callable</span> <span class=\"o\">=</span> <span class=\"nb\">getattr</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">event</span><span class=\"p\">,</span> <span class=\"kc\">None</span><span class=\"p\">)</span>\n",
       "            <span class=\"n\">callable</span> <span class=\"ow\">and</span> <span class=\"nb\">getattr</span><span class=\"p\">(</span><span class=\"n\">shell</span><span class=\"o\">.</span><span class=\"n\">events</span><span class=\"p\">,</span> <span class=\"sa\">f</span><span class=\"s2\">&quot;</span><span class=\"si\">{method}</span><span class=\"s2\">register&quot;</span><span class=\"p\">)(</span><span class=\"n\">event</span><span class=\"p\">,</span> <span class=\"n\">callable</span><span class=\"p\">)</span>\n",
       "        <span class=\"k\">if</span> <span class=\"nb\">isinstance</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">ast</span><span class=\"o\">.</span><span class=\"n\">NodeTransformer</span><span class=\"p\">):</span>\n",
       "            <span class=\"n\">register</span> <span class=\"ow\">and</span> <span class=\"n\">shell</span><span class=\"o\">.</span><span class=\"n\">ast_transformers</span><span class=\"o\">.</span><span class=\"n\">append</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">)</span>\n",
       "            <span class=\"n\">unregister</span> <span class=\"ow\">and</span> <span class=\"n\">shell</span><span class=\"o\">.</span><span class=\"n\">ast_transformers</span><span class=\"o\">.</span><span class=\"n\">pop</span><span class=\"p\">(</span>\n",
       "                <span class=\"n\">shell</span><span class=\"o\">.</span><span class=\"n\">ast_transformers</span><span class=\"o\">.</span><span class=\"n\">index</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">)</span>\n",
       "            <span class=\"p\">)</span>\n",
       "\n",
       "            <span class=\"k\">if</span> <span class=\"nb\">isinstance</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"n\">IPython</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">inputtransformer2</span><span class=\"o\">.</span><span class=\"n\">TransformerManager</span><span class=\"p\">):</span>\n",
       "                <span class=\"k\">if</span> <span class=\"n\">register</span><span class=\"p\">:</span>\n",
       "                    <span class=\"n\">shell</span><span class=\"o\">.</span><span class=\"n\">input_transformer_manager</span> <span class=\"o\">=</span> <span class=\"bp\">self</span>\n",
       "                <span class=\"k\">if</span> <span class=\"n\">unregister</span><span class=\"p\">:</span>\n",
       "                    <span class=\"n\">shell</span><span class=\"o\">.</span><span class=\"n\">input_transformer_managers</span> <span class=\"o\">=</span> <span class=\"p\">(</span>\n",
       "                        <span class=\"n\">IPython</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">inputtransformer2</span><span class=\"o\">.</span><span class=\"n\">TransformerManager</span><span class=\"p\">()</span>\n",
       "                    <span class=\"p\">)</span>\n",
       "\n",
       "        <span class=\"k\">return</span> <span class=\"bp\">self</span>\n",
       "\n",
       "    <span class=\"n\">unregister</span> <span class=\"o\">=</span> <span class=\"n\">functools</span><span class=\"o\">.</span><span class=\"n\">partialmethod</span><span class=\"p\">(</span><span class=\"n\">register</span><span class=\"p\">,</span> <span class=\"n\">method</span><span class=\"o\">=</span><span class=\"s2\">&quot;un&quot;</span><span class=\"p\">)</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{IPython}\\PY{o}{,} \\PY{n+nn}{ast}\\PY{o}{,} \\PY{n+nn}{dataclasses}\\PY{o}{,} \\PY{n+nn}{functools}\\PY{o}{,} \\PY{n+nn}{importnb}\n",
       "\n",
       "\n",
       "\\PY{n+nd}{@dataclasses}\\PY{o}{.}\\PY{n}{dataclass}\n",
       "\\PY{k}{class} \\PY{n+nc}{Extension}\\PY{p}{:}\n",
       "    \\PY{l+s+sd}{\\PYZdq{}\\PYZdq{}\\PYZdq{}`Extension` is base class that simplifies loading and unloading IPython extensions. Each component of `pidgy` is an IPython extension are this work compacts some repetative practices.\\PYZdq{}\\PYZdq{}\\PYZdq{}}\n",
       "\n",
       "    \\PY{n}{\\PYZus{}repl\\PYZus{}events} \\PY{o}{=} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{pre\\PYZus{}execute pre\\PYZus{}run\\PYZus{}cell post\\PYZus{}execute post\\PYZus{}run\\PYZus{}cell}\\PY{l+s+s2}{\\PYZdq{}}\\PY{o}{.}\\PY{n}{split}\\PY{p}{(}\\PY{p}{)}\n",
       "    \\PY{n}{shell}\\PY{p}{:} \\PY{n}{IPython}\\PY{o}{.}\\PY{n}{InteractiveShell} \\PY{o}{=} \\PY{n}{dataclasses}\\PY{o}{.}\\PY{n}{field}\\PY{p}{(}\n",
       "        \\PY{n}{default\\PYZus{}factory}\\PY{o}{=}\\PY{n}{IPython}\\PY{o}{.}\\PY{n}{get\\PYZus{}ipython}\n",
       "    \\PY{p}{)}\n",
       "\n",
       "    \\PY{k}{def} \\PY{n+nf}{register}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{shell}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{,} \\PY{o}{*}\\PY{p}{,} \\PY{n}{method}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{k}{if} \\PY{n}{shell}\\PY{p}{:}\n",
       "            \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{shell} \\PY{o}{=} \\PY{n}{shell}\n",
       "        \\PY{n}{register}\\PY{p}{,} \\PY{n}{unregister} \\PY{o}{=} \\PY{o+ow}{not} \\PY{n+nb}{bool}\\PY{p}{(}\\PY{n}{method}\\PY{p}{)}\\PY{p}{,} \\PY{n+nb}{bool}\\PY{p}{(}\\PY{n}{method}\\PY{p}{)}\n",
       "        \\PY{n}{shell} \\PY{o}{=} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{shell}\n",
       "        \\PY{k}{for} \\PY{n}{event} \\PY{o+ow}{in} \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{\\PYZus{}repl\\PYZus{}events}\\PY{p}{:}\n",
       "            \\PY{n}{callable} \\PY{o}{=} \\PY{n+nb}{getattr}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{event}\\PY{p}{,} \\PY{k+kc}{None}\\PY{p}{)}\n",
       "            \\PY{n}{callable} \\PY{o+ow}{and} \\PY{n+nb}{getattr}\\PY{p}{(}\\PY{n}{shell}\\PY{o}{.}\\PY{n}{events}\\PY{p}{,} \\PY{l+s+sa}{f}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+si}{\\PYZob{}method\\PYZcb{}}\\PY{l+s+s2}{register}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{(}\\PY{n}{event}\\PY{p}{,} \\PY{n}{callable}\\PY{p}{)}\n",
       "        \\PY{k}{if} \\PY{n+nb}{isinstance}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{ast}\\PY{o}{.}\\PY{n}{NodeTransformer}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{n}{register} \\PY{o+ow}{and} \\PY{n}{shell}\\PY{o}{.}\\PY{n}{ast\\PYZus{}transformers}\\PY{o}{.}\\PY{n}{append}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{)}\n",
       "            \\PY{n}{unregister} \\PY{o+ow}{and} \\PY{n}{shell}\\PY{o}{.}\\PY{n}{ast\\PYZus{}transformers}\\PY{o}{.}\\PY{n}{pop}\\PY{p}{(}\n",
       "                \\PY{n}{shell}\\PY{o}{.}\\PY{n}{ast\\PYZus{}transformers}\\PY{o}{.}\\PY{n}{index}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{)}\n",
       "            \\PY{p}{)}\n",
       "\n",
       "            \\PY{k}{if} \\PY{n+nb}{isinstance}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{n}{IPython}\\PY{o}{.}\\PY{n}{core}\\PY{o}{.}\\PY{n}{inputtransformer2}\\PY{o}{.}\\PY{n}{TransformerManager}\\PY{p}{)}\\PY{p}{:}\n",
       "                \\PY{k}{if} \\PY{n}{register}\\PY{p}{:}\n",
       "                    \\PY{n}{shell}\\PY{o}{.}\\PY{n}{input\\PYZus{}transformer\\PYZus{}manager} \\PY{o}{=} \\PY{n+nb+bp}{self}\n",
       "                \\PY{k}{if} \\PY{n}{unregister}\\PY{p}{:}\n",
       "                    \\PY{n}{shell}\\PY{o}{.}\\PY{n}{input\\PYZus{}transformer\\PYZus{}managers} \\PY{o}{=} \\PY{p}{(}\n",
       "                        \\PY{n}{IPython}\\PY{o}{.}\\PY{n}{core}\\PY{o}{.}\\PY{n}{inputtransformer2}\\PY{o}{.}\\PY{n}{TransformerManager}\\PY{p}{(}\\PY{p}{)}\n",
       "                    \\PY{p}{)}\n",
       "\n",
       "        \\PY{k}{return} \\PY{n+nb+bp}{self}\n",
       "\n",
       "    \\PY{n}{unregister} \\PY{o}{=} \\PY{n}{functools}\\PY{o}{.}\\PY{n}{partialmethod}\\PY{p}{(}\\PY{n}{register}\\PY{p}{,} \\PY{n}{method}\\PY{o}{=}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{un}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "import IPython, ast, dataclasses, functools, importnb\n",
       "\n",
       "\n",
       "@dataclasses.dataclass\n",
       "class Extension:\n",
       "    \"\"\"`Extension` is base class that simplifies loading and unloading IPython extensions. Each component of `pidgy` is an IPython extension are this work compacts some repetative practices.\"\"\"\n",
       "\n",
       "    _repl_events = \"pre_execute pre_run_cell post_execute post_run_cell\".split()\n",
       "    shell: IPython.InteractiveShell = dataclasses.field(\n",
       "        default_factory=IPython.get_ipython\n",
       "    )\n",
       "\n",
       "    def register(self, shell=None, *, method=\"\"):\n",
       "        if shell:\n",
       "            self.shell = shell\n",
       "        register, unregister = not bool(method), bool(method)\n",
       "        shell = self.shell\n",
       "        for event in self._repl_events:\n",
       "            callable = getattr(self, event, None)\n",
       "            callable and getattr(shell.events, f\"{method}register\")(event, callable)\n",
       "        if isinstance(self, ast.NodeTransformer):\n",
       "            register and shell.ast_transformers.append(self)\n",
       "            unregister and shell.ast_transformers.pop(\n",
       "                shell.ast_transformers.index(self)\n",
       "            )\n",
       "\n",
       "            if isinstance(self, IPython.core.inputtransformer2.TransformerManager):\n",
       "                if register:\n",
       "                    shell.input_transformer_manager = self\n",
       "                if unregister:\n",
       "                    shell.input_transformer_managers = (\n",
       "                        IPython.core.inputtransformer2.TransformerManager()\n",
       "                    )\n",
       "\n",
       "        return self\n",
       "\n",
       "    unregister = functools.partialmethod(register, method=\"un\")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/markdown": [
       "    IPython.display.Code(filename=pidgy.base.__file__, language='python')"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    IPython.display.Code(filename=pidgy.base.__file__, language='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### `pidgy` utilities."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### `pidgy` utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.output_html .hll { background-color: #ffffcc }\n",
       ".output_html  { background: #f8f8f8; }\n",
       ".output_html .c { color: #408080; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #408080; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #408080; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #BC7A00 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #408080; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #408080; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .gr { color: #FF0000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #00A000 } /* Generic.Inserted */\n",
       ".output_html .go { color: #888888 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #7D9029 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #999999; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #D2413A; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #A0A000 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #BB6688 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">re</span><span class=\"o\">,</span> <span class=\"nn\">typing</span>\n",
       "\n",
       "\n",
       "<span class=\"k\">class</span> <span class=\"nc\">ContextDepth</span><span class=\"p\">:</span>\n",
       "    <span class=\"n\">depth</span> <span class=\"o\">=</span> <span class=\"mi\">0</span>\n",
       "\n",
       "    <span class=\"k\">def</span> <span class=\"fm\">__enter__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">):</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">depth</span> <span class=\"o\">+=</span> <span class=\"mi\">1</span>\n",
       "\n",
       "    <span class=\"k\">def</span> <span class=\"fm\">__exit__</span><span class=\"p\">(</span><span class=\"bp\">self</span><span class=\"p\">,</span> <span class=\"o\">*</span><span class=\"n\">e</span><span class=\"p\">):</span>\n",
       "        <span class=\"bp\">self</span><span class=\"o\">.</span><span class=\"n\">depth</span> <span class=\"o\">-=</span> <span class=\"mi\">1</span>\n",
       "\n",
       "\n",
       "<span class=\"p\">(</span><span class=\"n\">FENCE</span><span class=\"p\">,</span> <span class=\"n\">CONTINUATION</span><span class=\"p\">,</span> <span class=\"n\">SEMI</span><span class=\"p\">,</span> <span class=\"n\">COLON</span><span class=\"p\">,</span> <span class=\"n\">MAGIC</span><span class=\"p\">,</span> <span class=\"n\">DOCTEST</span><span class=\"p\">),</span> <span class=\"n\">QUOTES</span><span class=\"p\">,</span> <span class=\"n\">SPACE</span> <span class=\"o\">=</span> <span class=\"p\">(</span>\n",
       "    <span class=\"s2\">&quot;``` </span><span class=\"se\">\\\\</span><span class=\"s2\"> ; : </span><span class=\"si\">%%</span><span class=\"s2\"> &gt;&gt;&gt;&quot;</span><span class=\"o\">.</span><span class=\"n\">split</span><span class=\"p\">(),</span>\n",
       "    <span class=\"p\">(</span><span class=\"s1\">&#39;&quot;&quot;&quot;&#39;</span><span class=\"p\">,</span> <span class=\"s2\">&quot;&#39;&#39;&#39;&quot;</span><span class=\"p\">),</span>\n",
       "    <span class=\"s2\">&quot; &quot;</span><span class=\"p\">,</span>\n",
       "<span class=\"p\">)</span>\n",
       "<span class=\"n\">WHITESPACE</span> <span class=\"o\">=</span> <span class=\"n\">re</span><span class=\"o\">.</span><span class=\"n\">compile</span><span class=\"p\">(</span><span class=\"s2\">&quot;^\\s*&quot;</span><span class=\"p\">,</span> <span class=\"n\">re</span><span class=\"o\">.</span><span class=\"n\">MULTILINE</span><span class=\"p\">)</span>\n",
       "\n",
       "\n",
       "<span class=\"k\">def</span> <span class=\"nf\">num_first_indent</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"p\">:</span> <span class=\"nb\">str</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"nb\">int</span><span class=\"p\">:</span>\n",
       "    <span class=\"k\">for</span> <span class=\"nb\">str</span> <span class=\"ow\">in</span> <span class=\"n\">text</span><span class=\"o\">.</span><span class=\"n\">splitlines</span><span class=\"p\">():</span>\n",
       "        <span class=\"k\">if</span> <span class=\"nb\">str</span><span class=\"o\">.</span><span class=\"n\">strip</span><span class=\"p\">():</span>\n",
       "            <span class=\"k\">return</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"nb\">str</span><span class=\"p\">)</span> <span class=\"o\">-</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"nb\">str</span><span class=\"o\">.</span><span class=\"n\">lstrip</span><span class=\"p\">())</span>\n",
       "    <span class=\"k\">return</span> <span class=\"mi\">0</span>\n",
       "\n",
       "\n",
       "<span class=\"k\">def</span> <span class=\"nf\">num_last_indent</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"p\">:</span> <span class=\"nb\">str</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"nb\">int</span><span class=\"p\">:</span>\n",
       "    <span class=\"k\">for</span> <span class=\"nb\">str</span> <span class=\"ow\">in</span> <span class=\"nb\">reversed</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">.</span><span class=\"n\">splitlines</span><span class=\"p\">()):</span>\n",
       "        <span class=\"k\">if</span> <span class=\"nb\">str</span><span class=\"o\">.</span><span class=\"n\">strip</span><span class=\"p\">():</span>\n",
       "            <span class=\"k\">return</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"nb\">str</span><span class=\"p\">)</span> <span class=\"o\">-</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"nb\">str</span><span class=\"o\">.</span><span class=\"n\">lstrip</span><span class=\"p\">())</span>\n",
       "    <span class=\"k\">return</span> <span class=\"mi\">0</span>\n",
       "\n",
       "\n",
       "<span class=\"k\">def</span> <span class=\"nf\">base_indent</span><span class=\"p\">(</span><span class=\"n\">tokens</span><span class=\"p\">:</span> <span class=\"n\">typing</span><span class=\"o\">.</span><span class=\"n\">List</span><span class=\"p\">[</span><span class=\"nb\">dict</span><span class=\"p\">])</span> <span class=\"o\">-&gt;</span> <span class=\"nb\">int</span><span class=\"p\">:</span>\n",
       "    <span class=\"s2\">&quot;Look ahead for the base indent.&quot;</span>\n",
       "    <span class=\"k\">for</span> <span class=\"n\">i</span><span class=\"p\">,</span> <span class=\"n\">token</span> <span class=\"ow\">in</span> <span class=\"nb\">enumerate</span><span class=\"p\">(</span><span class=\"n\">tokens</span><span class=\"p\">):</span>\n",
       "        <span class=\"k\">if</span> <span class=\"n\">token</span><span class=\"p\">[</span><span class=\"s2\">&quot;type&quot;</span><span class=\"p\">]</span> <span class=\"o\">==</span> <span class=\"s2\">&quot;code&quot;</span><span class=\"p\">:</span>\n",
       "            <span class=\"n\">code</span> <span class=\"o\">=</span> <span class=\"n\">token</span><span class=\"p\">[</span><span class=\"s2\">&quot;text&quot;</span><span class=\"p\">]</span>\n",
       "            <span class=\"k\">if</span> <span class=\"n\">code</span><span class=\"o\">.</span><span class=\"n\">lstrip</span><span class=\"p\">()</span><span class=\"o\">.</span><span class=\"n\">startswith</span><span class=\"p\">(</span><span class=\"n\">FENCE</span><span class=\"p\">):</span>\n",
       "                <span class=\"k\">continue</span>\n",
       "            <span class=\"n\">indent</span> <span class=\"o\">=</span> <span class=\"n\">num_first_indent</span><span class=\"p\">(</span><span class=\"n\">code</span><span class=\"p\">)</span>\n",
       "            <span class=\"k\">break</span>\n",
       "    <span class=\"k\">else</span><span class=\"p\">:</span>\n",
       "        <span class=\"n\">indent</span> <span class=\"o\">=</span> <span class=\"mi\">4</span>\n",
       "    <span class=\"k\">return</span> <span class=\"n\">indent</span>\n",
       "\n",
       "\n",
       "<span class=\"k\">def</span> <span class=\"nf\">quote</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"p\">:</span> <span class=\"nb\">str</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"nb\">str</span><span class=\"p\">:</span>\n",
       "    <span class=\"sd\">&quot;&quot;&quot;wrap text in `QUOTES`&quot;&quot;&quot;</span>\n",
       "    <span class=\"k\">if</span> <span class=\"n\">text</span><span class=\"o\">.</span><span class=\"n\">strip</span><span class=\"p\">():</span>\n",
       "        <span class=\"n\">left</span><span class=\"p\">,</span> <span class=\"n\">right</span> <span class=\"o\">=</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"p\">)</span> <span class=\"o\">-</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">.</span><span class=\"n\">lstrip</span><span class=\"p\">()),</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">.</span><span class=\"n\">rstrip</span><span class=\"p\">())</span>\n",
       "        <span class=\"n\">quote</span> <span class=\"o\">=</span> <span class=\"n\">QUOTES</span><span class=\"p\">[(</span><span class=\"n\">text</span><span class=\"p\">[</span><span class=\"n\">right</span> <span class=\"o\">-</span> <span class=\"mi\">1</span><span class=\"p\">]</span> <span class=\"ow\">in</span> <span class=\"n\">QUOTES</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">])</span> <span class=\"ow\">or</span> <span class=\"p\">(</span><span class=\"n\">QUOTES</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span> <span class=\"ow\">in</span> <span class=\"n\">text</span><span class=\"p\">)]</span>\n",
       "        <span class=\"k\">return</span> <span class=\"n\">text</span><span class=\"p\">[:</span><span class=\"n\">left</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">quote</span> <span class=\"o\">+</span> <span class=\"n\">text</span><span class=\"p\">[</span><span class=\"n\">left</span><span class=\"p\">:</span><span class=\"n\">right</span><span class=\"p\">]</span> <span class=\"o\">+</span> <span class=\"n\">quote</span> <span class=\"o\">+</span> <span class=\"n\">text</span><span class=\"p\">[</span><span class=\"n\">right</span><span class=\"p\">:]</span>\n",
       "    <span class=\"k\">return</span> <span class=\"n\">text</span>\n",
       "\n",
       "\n",
       "<span class=\"k\">def</span> <span class=\"nf\">num_whitespace</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"p\">:</span> <span class=\"nb\">str</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"nb\">int</span><span class=\"p\">:</span>\n",
       "    <span class=\"k\">return</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"p\">)</span> <span class=\"o\">-</span> <span class=\"nb\">len</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"o\">.</span><span class=\"n\">lstrip</span><span class=\"p\">())</span>\n",
       "\n",
       "\n",
       "<span class=\"k\">def</span> <span class=\"nf\">whiten</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"p\">:</span> <span class=\"nb\">str</span><span class=\"p\">)</span> <span class=\"o\">-&gt;</span> <span class=\"nb\">str</span><span class=\"p\">:</span>\n",
       "    <span class=\"sd\">&quot;&quot;&quot;`whiten` strips empty lines because the `markdown.BlockLexer` doesn&#39;t like that.&quot;&quot;&quot;</span>\n",
       "    <span class=\"k\">return</span> <span class=\"s2\">&quot;</span><span class=\"se\">\\n</span><span class=\"s2\">&quot;</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"o\">.</span><span class=\"n\">rstrip</span><span class=\"p\">()</span> <span class=\"k\">for</span> <span class=\"n\">x</span> <span class=\"ow\">in</span> <span class=\"n\">text</span><span class=\"o\">.</span><span class=\"n\">splitlines</span><span class=\"p\">())</span>\n",
       "\n",
       "\n",
       "<span class=\"k\">def</span> <span class=\"nf\">strip_front_matter</span><span class=\"p\">(</span><span class=\"n\">text</span><span class=\"p\">,</span> <span class=\"n\">sep</span><span class=\"o\">=</span><span class=\"kc\">None</span><span class=\"p\">):</span>\n",
       "    <span class=\"k\">if</span> <span class=\"n\">text</span><span class=\"o\">.</span><span class=\"n\">startswith</span><span class=\"p\">(</span><span class=\"s2\">&quot;---</span><span class=\"se\">\\n</span><span class=\"s2\">&quot;</span><span class=\"p\">):</span>\n",
       "        <span class=\"n\">front_matter</span><span class=\"p\">,</span> <span class=\"n\">sep</span><span class=\"p\">,</span> <span class=\"n\">rest</span> <span class=\"o\">=</span> <span class=\"n\">text</span><span class=\"p\">[</span><span class=\"mi\">4</span><span class=\"p\">:]</span><span class=\"o\">.</span><span class=\"n\">partition</span><span class=\"p\">(</span><span class=\"s2\">&quot;</span><span class=\"se\">\\n</span><span class=\"s2\">---&quot;</span><span class=\"p\">)</span>\n",
       "    <span class=\"k\">if</span> <span class=\"n\">sep</span><span class=\"p\">:</span>\n",
       "        <span class=\"k\">return</span> <span class=\"s2\">&quot;&quot;</span><span class=\"o\">.</span><span class=\"n\">join</span><span class=\"p\">(</span><span class=\"n\">rest</span><span class=\"o\">.</span><span class=\"n\">splitlines</span><span class=\"p\">(</span><span class=\"kc\">True</span><span class=\"p\">)[</span><span class=\"mi\">1</span><span class=\"p\">:])</span>\n",
       "    <span class=\"k\">return</span> <span class=\"n\">text</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{k+kn}{import} \\PY{n+nn}{re}\\PY{o}{,} \\PY{n+nn}{typing}\n",
       "\n",
       "\n",
       "\\PY{k}{class} \\PY{n+nc}{ContextDepth}\\PY{p}{:}\n",
       "    \\PY{n}{depth} \\PY{o}{=} \\PY{l+m+mi}{0}\n",
       "\n",
       "    \\PY{k}{def} \\PY{n+nf+fm}{\\PYZus{}\\PYZus{}enter\\PYZus{}\\PYZus{}}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{depth} \\PY{o}{+}\\PY{o}{=} \\PY{l+m+mi}{1}\n",
       "\n",
       "    \\PY{k}{def} \\PY{n+nf+fm}{\\PYZus{}\\PYZus{}exit\\PYZus{}\\PYZus{}}\\PY{p}{(}\\PY{n+nb+bp}{self}\\PY{p}{,} \\PY{o}{*}\\PY{n}{e}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n+nb+bp}{self}\\PY{o}{.}\\PY{n}{depth} \\PY{o}{\\PYZhy{}}\\PY{o}{=} \\PY{l+m+mi}{1}\n",
       "\n",
       "\n",
       "\\PY{p}{(}\\PY{n}{FENCE}\\PY{p}{,} \\PY{n}{CONTINUATION}\\PY{p}{,} \\PY{n}{SEMI}\\PY{p}{,} \\PY{n}{COLON}\\PY{p}{,} \\PY{n}{MAGIC}\\PY{p}{,} \\PY{n}{DOCTEST}\\PY{p}{)}\\PY{p}{,} \\PY{n}{QUOTES}\\PY{p}{,} \\PY{n}{SPACE} \\PY{o}{=} \\PY{p}{(}\n",
       "    \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{``` }\\PY{l+s+se}{\\PYZbs{}\\PYZbs{}}\\PY{l+s+s2}{ ; : }\\PY{l+s+si}{\\PYZpc{}\\PYZpc{}}\\PY{l+s+s2}{ \\PYZgt{}\\PYZgt{}\\PYZgt{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{o}{.}\\PY{n}{split}\\PY{p}{(}\\PY{p}{)}\\PY{p}{,}\n",
       "    \\PY{p}{(}\\PY{l+s+s1}{\\PYZsq{}}\\PY{l+s+s1}{\\PYZdq{}}\\PY{l+s+s1}{\\PYZdq{}}\\PY{l+s+s1}{\\PYZdq{}}\\PY{l+s+s1}{\\PYZsq{}}\\PY{p}{,} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{\\PYZsq{}}\\PY{l+s+s2}{\\PYZsq{}}\\PY{l+s+s2}{\\PYZsq{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{,}\n",
       "    \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{ }\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,}\n",
       "\\PY{p}{)}\n",
       "\\PY{n}{WHITESPACE} \\PY{o}{=} \\PY{n}{re}\\PY{o}{.}\\PY{n}{compile}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{\\PYZca{}}\\PY{l+s+s2}{\\PYZbs{}}\\PY{l+s+s2}{s*}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{,} \\PY{n}{re}\\PY{o}{.}\\PY{n}{MULTILINE}\\PY{p}{)}\n",
       "\n",
       "\n",
       "\\PY{k}{def} \\PY{n+nf}{num\\PYZus{}first\\PYZus{}indent}\\PY{p}{(}\\PY{n}{text}\\PY{p}{:} \\PY{n+nb}{str}\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n+nb}{int}\\PY{p}{:}\n",
       "    \\PY{k}{for} \\PY{n+nb}{str} \\PY{o+ow}{in} \\PY{n}{text}\\PY{o}{.}\\PY{n}{splitlines}\\PY{p}{(}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{k}{if} \\PY{n+nb}{str}\\PY{o}{.}\\PY{n}{strip}\\PY{p}{(}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{k}{return} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n+nb}{str}\\PY{p}{)} \\PY{o}{\\PYZhy{}} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n+nb}{str}\\PY{o}{.}\\PY{n}{lstrip}\\PY{p}{(}\\PY{p}{)}\\PY{p}{)}\n",
       "    \\PY{k}{return} \\PY{l+m+mi}{0}\n",
       "\n",
       "\n",
       "\\PY{k}{def} \\PY{n+nf}{num\\PYZus{}last\\PYZus{}indent}\\PY{p}{(}\\PY{n}{text}\\PY{p}{:} \\PY{n+nb}{str}\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n+nb}{int}\\PY{p}{:}\n",
       "    \\PY{k}{for} \\PY{n+nb}{str} \\PY{o+ow}{in} \\PY{n+nb}{reversed}\\PY{p}{(}\\PY{n}{text}\\PY{o}{.}\\PY{n}{splitlines}\\PY{p}{(}\\PY{p}{)}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{k}{if} \\PY{n+nb}{str}\\PY{o}{.}\\PY{n}{strip}\\PY{p}{(}\\PY{p}{)}\\PY{p}{:}\n",
       "            \\PY{k}{return} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n+nb}{str}\\PY{p}{)} \\PY{o}{\\PYZhy{}} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n+nb}{str}\\PY{o}{.}\\PY{n}{lstrip}\\PY{p}{(}\\PY{p}{)}\\PY{p}{)}\n",
       "    \\PY{k}{return} \\PY{l+m+mi}{0}\n",
       "\n",
       "\n",
       "\\PY{k}{def} \\PY{n+nf}{base\\PYZus{}indent}\\PY{p}{(}\\PY{n}{tokens}\\PY{p}{:} \\PY{n}{typing}\\PY{o}{.}\\PY{n}{List}\\PY{p}{[}\\PY{n+nb}{dict}\\PY{p}{]}\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n+nb}{int}\\PY{p}{:}\n",
       "    \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{Look ahead for the base indent.}\\PY{l+s+s2}{\\PYZdq{}}\n",
       "    \\PY{k}{for} \\PY{n}{i}\\PY{p}{,} \\PY{n}{token} \\PY{o+ow}{in} \\PY{n+nb}{enumerate}\\PY{p}{(}\\PY{n}{tokens}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{k}{if} \\PY{n}{token}\\PY{p}{[}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{type}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]} \\PY{o}{==} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{code}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{:}\n",
       "            \\PY{n}{code} \\PY{o}{=} \\PY{n}{token}\\PY{p}{[}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{text}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{]}\n",
       "            \\PY{k}{if} \\PY{n}{code}\\PY{o}{.}\\PY{n}{lstrip}\\PY{p}{(}\\PY{p}{)}\\PY{o}{.}\\PY{n}{startswith}\\PY{p}{(}\\PY{n}{FENCE}\\PY{p}{)}\\PY{p}{:}\n",
       "                \\PY{k}{continue}\n",
       "            \\PY{n}{indent} \\PY{o}{=} \\PY{n}{num\\PYZus{}first\\PYZus{}indent}\\PY{p}{(}\\PY{n}{code}\\PY{p}{)}\n",
       "            \\PY{k}{break}\n",
       "    \\PY{k}{else}\\PY{p}{:}\n",
       "        \\PY{n}{indent} \\PY{o}{=} \\PY{l+m+mi}{4}\n",
       "    \\PY{k}{return} \\PY{n}{indent}\n",
       "\n",
       "\n",
       "\\PY{k}{def} \\PY{n+nf}{quote}\\PY{p}{(}\\PY{n}{text}\\PY{p}{:} \\PY{n+nb}{str}\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n+nb}{str}\\PY{p}{:}\n",
       "    \\PY{l+s+sd}{\\PYZdq{}\\PYZdq{}\\PYZdq{}wrap text in `QUOTES`\\PYZdq{}\\PYZdq{}\\PYZdq{}}\n",
       "    \\PY{k}{if} \\PY{n}{text}\\PY{o}{.}\\PY{n}{strip}\\PY{p}{(}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n}{left}\\PY{p}{,} \\PY{n}{right} \\PY{o}{=} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{text}\\PY{p}{)} \\PY{o}{\\PYZhy{}} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{text}\\PY{o}{.}\\PY{n}{lstrip}\\PY{p}{(}\\PY{p}{)}\\PY{p}{)}\\PY{p}{,} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{text}\\PY{o}{.}\\PY{n}{rstrip}\\PY{p}{(}\\PY{p}{)}\\PY{p}{)}\n",
       "        \\PY{n}{quote} \\PY{o}{=} \\PY{n}{QUOTES}\\PY{p}{[}\\PY{p}{(}\\PY{n}{text}\\PY{p}{[}\\PY{n}{right} \\PY{o}{\\PYZhy{}} \\PY{l+m+mi}{1}\\PY{p}{]} \\PY{o+ow}{in} \\PY{n}{QUOTES}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{]}\\PY{p}{)} \\PY{o+ow}{or} \\PY{p}{(}\\PY{n}{QUOTES}\\PY{p}{[}\\PY{l+m+mi}{0}\\PY{p}{]} \\PY{o+ow}{in} \\PY{n}{text}\\PY{p}{)}\\PY{p}{]}\n",
       "        \\PY{k}{return} \\PY{n}{text}\\PY{p}{[}\\PY{p}{:}\\PY{n}{left}\\PY{p}{]} \\PY{o}{+} \\PY{n}{quote} \\PY{o}{+} \\PY{n}{text}\\PY{p}{[}\\PY{n}{left}\\PY{p}{:}\\PY{n}{right}\\PY{p}{]} \\PY{o}{+} \\PY{n}{quote} \\PY{o}{+} \\PY{n}{text}\\PY{p}{[}\\PY{n}{right}\\PY{p}{:}\\PY{p}{]}\n",
       "    \\PY{k}{return} \\PY{n}{text}\n",
       "\n",
       "\n",
       "\\PY{k}{def} \\PY{n+nf}{num\\PYZus{}whitespace}\\PY{p}{(}\\PY{n}{text}\\PY{p}{:} \\PY{n+nb}{str}\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n+nb}{int}\\PY{p}{:}\n",
       "    \\PY{k}{return} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{text}\\PY{p}{)} \\PY{o}{\\PYZhy{}} \\PY{n+nb}{len}\\PY{p}{(}\\PY{n}{text}\\PY{o}{.}\\PY{n}{lstrip}\\PY{p}{(}\\PY{p}{)}\\PY{p}{)}\n",
       "\n",
       "\n",
       "\\PY{k}{def} \\PY{n+nf}{whiten}\\PY{p}{(}\\PY{n}{text}\\PY{p}{:} \\PY{n+nb}{str}\\PY{p}{)} \\PY{o}{\\PYZhy{}}\\PY{o}{\\PYZgt{}} \\PY{n+nb}{str}\\PY{p}{:}\n",
       "    \\PY{l+s+sd}{\\PYZdq{}\\PYZdq{}\\PYZdq{}`whiten` strips empty lines because the `markdown.BlockLexer` doesn\\PYZsq{}t like that.\\PYZdq{}\\PYZdq{}\\PYZdq{}}\n",
       "    \\PY{k}{return} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+se}{\\PYZbs{}n}\\PY{l+s+s2}{\\PYZdq{}}\\PY{o}{.}\\PY{n}{join}\\PY{p}{(}\\PY{n}{x}\\PY{o}{.}\\PY{n}{rstrip}\\PY{p}{(}\\PY{p}{)} \\PY{k}{for} \\PY{n}{x} \\PY{o+ow}{in} \\PY{n}{text}\\PY{o}{.}\\PY{n}{splitlines}\\PY{p}{(}\\PY{p}{)}\\PY{p}{)}\n",
       "\n",
       "\n",
       "\\PY{k}{def} \\PY{n+nf}{strip\\PYZus{}front\\PYZus{}matter}\\PY{p}{(}\\PY{n}{text}\\PY{p}{,} \\PY{n}{sep}\\PY{o}{=}\\PY{k+kc}{None}\\PY{p}{)}\\PY{p}{:}\n",
       "    \\PY{k}{if} \\PY{n}{text}\\PY{o}{.}\\PY{n}{startswith}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{\\PYZhy{}\\PYZhy{}\\PYZhy{}}\\PY{l+s+se}{\\PYZbs{}n}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\\PY{p}{:}\n",
       "        \\PY{n}{front\\PYZus{}matter}\\PY{p}{,} \\PY{n}{sep}\\PY{p}{,} \\PY{n}{rest} \\PY{o}{=} \\PY{n}{text}\\PY{p}{[}\\PY{l+m+mi}{4}\\PY{p}{:}\\PY{p}{]}\\PY{o}{.}\\PY{n}{partition}\\PY{p}{(}\\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+se}{\\PYZbs{}n}\\PY{l+s+s2}{\\PYZhy{}\\PYZhy{}\\PYZhy{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{p}{)}\n",
       "    \\PY{k}{if} \\PY{n}{sep}\\PY{p}{:}\n",
       "        \\PY{k}{return} \\PY{l+s+s2}{\\PYZdq{}}\\PY{l+s+s2}{\\PYZdq{}}\\PY{o}{.}\\PY{n}{join}\\PY{p}{(}\\PY{n}{rest}\\PY{o}{.}\\PY{n}{splitlines}\\PY{p}{(}\\PY{k+kc}{True}\\PY{p}{)}\\PY{p}{[}\\PY{l+m+mi}{1}\\PY{p}{:}\\PY{p}{]}\\PY{p}{)}\n",
       "    \\PY{k}{return} \\PY{n}{text}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "import re, typing\n",
       "\n",
       "\n",
       "class ContextDepth:\n",
       "    depth = 0\n",
       "\n",
       "    def __enter__(self):\n",
       "        self.depth += 1\n",
       "\n",
       "    def __exit__(self, *e):\n",
       "        self.depth -= 1\n",
       "\n",
       "\n",
       "(FENCE, CONTINUATION, SEMI, COLON, MAGIC, DOCTEST), QUOTES, SPACE = (\n",
       "    \"``` \\\\ ; : %% >>>\".split(),\n",
       "    ('\"\"\"', \"'''\"),\n",
       "    \" \",\n",
       ")\n",
       "WHITESPACE = re.compile(\"^\\s*\", re.MULTILINE)\n",
       "\n",
       "\n",
       "def num_first_indent(text: str) -> int:\n",
       "    for str in text.splitlines():\n",
       "        if str.strip():\n",
       "            return len(str) - len(str.lstrip())\n",
       "    return 0\n",
       "\n",
       "\n",
       "def num_last_indent(text: str) -> int:\n",
       "    for str in reversed(text.splitlines()):\n",
       "        if str.strip():\n",
       "            return len(str) - len(str.lstrip())\n",
       "    return 0\n",
       "\n",
       "\n",
       "def base_indent(tokens: typing.List[dict]) -> int:\n",
       "    \"Look ahead for the base indent.\"\n",
       "    for i, token in enumerate(tokens):\n",
       "        if token[\"type\"] == \"code\":\n",
       "            code = token[\"text\"]\n",
       "            if code.lstrip().startswith(FENCE):\n",
       "                continue\n",
       "            indent = num_first_indent(code)\n",
       "            break\n",
       "    else:\n",
       "        indent = 4\n",
       "    return indent\n",
       "\n",
       "\n",
       "def quote(text: str) -> str:\n",
       "    \"\"\"wrap text in `QUOTES`\"\"\"\n",
       "    if text.strip():\n",
       "        left, right = len(text) - len(text.lstrip()), len(text.rstrip())\n",
       "        quote = QUOTES[(text[right - 1] in QUOTES[0]) or (QUOTES[0] in text)]\n",
       "        return text[:left] + quote + text[left:right] + quote + text[right:]\n",
       "    return text\n",
       "\n",
       "\n",
       "def num_whitespace(text: str) -> int:\n",
       "    return len(text) - len(text.lstrip())\n",
       "\n",
       "\n",
       "def whiten(text: str) -> str:\n",
       "    \"\"\"`whiten` strips empty lines because the `markdown.BlockLexer` doesn't like that.\"\"\"\n",
       "    return \"\\n\".join(x.rstrip() for x in text.splitlines())\n",
       "\n",
       "\n",
       "def strip_front_matter(text, sep=None):\n",
       "    if text.startswith(\"---\\n\"):\n",
       "        front_matter, sep, rest = text[4:].partition(\"\\n---\")\n",
       "    if sep:\n",
       "        return \"\".join(rest.splitlines(True)[1:])\n",
       "    return text"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/markdown": [
       "    IPython.display.Code(filename=pidgy.util.__file__, language='python')"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    IPython.display.Code(filename=pidgy.util.__file__, language='python')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook index.md.ipynb to markdown\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "    # NBVAL_SKIP\n",
       "\n",
       "    \n",
       "    if __name__ == '__main__' and not '__file__' in globals():\n",
       "        !jupyter nbconvert --to markdown --stdout --TemplateExporter.exclude_input=True index.md.ipynb > docs/index.md\n",
       "\n",
       "-->"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    # NBVAL_SKIP\n",
    "\n",
    "    \n",
    "    if __name__ == '__main__' and not '__file__' in globals():\n",
    "        !jupyter nbconvert --to markdown --stdout --TemplateExporter.exclude_input=True index.md.ipynb > docs/index.md\n",
    "\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pidgy 3",
   "language": "python",
   "name": "pidgy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
